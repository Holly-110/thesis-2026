\documentclass[dvipdfmx]{thesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 基本設定

%\論文名{2025年度 修士論文}
\論文名{2026年度 卒業論文}
%\所属{岐阜大学大学院 自然科学技術研究科 知能理工学専攻 知能情報学領域
\所属{岐阜大学 工学部 電気電子・情報工学科 情報コース}
\学生番号{1243440498}
\氏名{伊藤 柊太朗}
\指導教員{松本 忠博}
\題目{日本語アスペクトカテゴリ感情分析における推論過程の導入による有効性検証}
%\日付{2026年2月x日}
\日付{2026年2月}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ユーザ定義

% …… ご自由に定義してください ……
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
% 図のディレクトリ
\graphicspath{{./pics/}}
\usepackage{booktabs}    % 高品質な横線（\toprule, \midrule, \bottomrule）を使うため
\usepackage{multirow}    % セルを縦方向に結合するため
\usepackage{array}       % 表の列幅指定や配置を細かく制御するため
\usepackage{amssymb} % \pm 記号用
\usepackage{graphicx}
\usepackage[table]{xcolor} % 表の網掛け用

% 定理，定義
%\usepackage{amsthm}
%\theoremstyle{definition}
\newtheorem{theorem}{定理}
\newtheorem{definition}[theorem]{定義}
%\newtheorem*{definition*}{定義}
\newtheorem{example}{例}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 表紙と目次 (以下はお約束の呪文)
\begin{document}
\maketitle
\frontmatter
\tableofcontents
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{序論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{研究背景}
 近年，インターネットおよび電子商取引やSNSの普及に伴い，オンライン上のユーザ生成コンテンツ(レビューやSNS投稿など)が爆発的に増加している．これらのレビューや投稿から個々のユーザの意見を分析・理解することは，製品やサービスの改善，およびマーケティング戦略の立案において不可欠である．しかし，膨大なテキストデータを人手で処理することは非効率的であり，多大なコストを要する．そのため，近年は機械学習や深層学習を用いた自然言語処理技術による感情分析が幅広く研究されている．
 
従来のユーザ生成コンテンツに対する感情分析は，文や文書全体に対してポジティブ，ネガティブ，あるいはニュートラルのいずれか一意の感情極性を判定する手法が主流である．しかし，実際には一つの文中に複数のトピックが含まれ，それぞれのトピックに対して異なる感情が示されることも少なくない．例えば，「料理はおいしいが，店員の態度が悪かった」といったレストランのレビュー文がある場合に，このレビュー文は，「料理」に対してはポジティブな評価であるが，「店員の態度」に対してはネガティブな評価である．上記の例のように，一文に対して単一の感情極性を割り当てるだけでは，ユーザの多面的な意見を正確に捉えることは困難である．このような課題に対し，文中に含まれるアスペクト（トピック）ごとに感情を判定する手法をアスペクトベース感情分析(Aspect-Based Sentiment Analysis; 以下, ABSA)という．アスペクトベース感情分析は，従来の感情分析と比較して細粒度な分析が可能であり，ECサイトのレビュー文分析など多くの場面での実用化が期待され，研究が行われている．
 
しかし，アスペクトベース感情分析はその対象の細かさから，データセットのアノテーションコストが従来の感情分析よりも高いというデメリットがあり，日本語でのデータセット数はかなり少ない．その影響もあり，日本語を対象としたアスペクトベース感情分析の研究はいまだ限定的であるという課題が残されている．

\section{研究の目的}
本研究の目的は，日本語ABSAデータセットとしてよく利用される楽天トラベルレビューデータセットを使用し，ABSAのサブタスクの一つである，アスペクトカテゴリ感情分類（Aspect Category Sentiment Analysis; 以下, ACSA）の精度を向上させることである．
具体的には，従来の文全体を入力とし、ラベルを予測する手法ではなく、日本語事前学習済みT5モデルを用いたSeq2Seqモデリングを採用することで入力文に対し、感情要素を含むターゲットシーケンスを生成することを可能にする。これにより表現の幅を広げ、単一の学習モデルによる高精度な分析を目指す．さらに，大規模言語モデルの持つ推論能力を学習に取り入れるFine-tune-CoT手法を用いることで、中間推論過程を明示的にし、なぜその結論に至ったかという思考のプロセスは明確にすることで、生成モデルの解釈能力と予測精度のさらなる向上を検証する。

\section{論文の構成}
本論文の第2章以降の構成を以下に示す。 

\begin{itemize}
    \item \textbf{第2章：事前知識} \\
    本研究の基礎となるアスペクトベース感情分析（ABSA）の定義，および本研究で使用する言語モデルや推論手法に関する事前知識について説明する．
    
    \item \textbf{第3章：関連研究} \\
    日本語ABSAに関する先行研究を概観し，既存の分類手法との違いや本研究の立ち位置について述べる．
    
    \item \textbf{第4章：予備実験：T5モデルによる直接生成手法} \\
    予備実験としてT5モデルを用いた直接生成手法（ベースライン）による検証を行い，ベースラインにおける課題について議論する．
    
    \item \textbf{第5章：提案手法：Fine-tune-CoTを用いた推論過程の導入} \\
    前章で明らかになった課題を解決するための提案手法として，Fine-tune-CoT手法を用いた中間推論過程の導入について説明する．
    
    \item \textbf{第6章：評価実験} \\
    提案手法の有効性を検証するための評価実験を行い，ベースライン手法との推論精度の定量分析結果や定性分析結果について述べる．
    
    \item \textbf{第7章：結論} \\
    本研究で得られた知見をまとめ，結論と今後の課題について述べる．
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{事前知識}
本章では、研究を理解する上で必要となる事前知識について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{アスペクトベース感情分析 (ABSA)}

\subsection{ABSAの定義と4要素}
1章でも述べた通り、従来の感情分析が，文や文書全体に対して一つの感情極性を判定するのに対し，アスペクトベース感情分析は，より細かな分析を行うタスクである ABSAでは，主に以下の4つの感情要素を扱う．Zhangら \cite{survey} は，ABSAの問題を「テキスト中の関心のある感情要素（単一または複数の組み合わせ）を特定する問題」と定義している．

\begin{enumerate}
    \item \textbf{アスペクト用語 ($a$)}:
    文中に明示的に現れる評価対象の単語
    
    （例：「\textbf{ピザ}はおいしい」における「ピザ」）．

    \item \textbf{アスペクトカテゴリ ($c$)}:
    ドメインごとに事前に定義されたカテゴリ
    
    （例：レストランドメインにおける「食べ物」，「サービス」など）．
    
    \item \textbf{意見用語 ($o$)}:
    評価対象に対する感情や判断を表す語句
    
    （例：「ピザは\textbf{おいしい}」における「おいしい」）．
    
    \item \textbf{感情極性 ($p$)}:
    感情の方向性
    
    （例：ポジティブ，ネガティブ，ニュートラル）．
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\columnwidth]{pics/ABSA_base.png} % フォルダ名/ファイル名
  \caption{ABSAの4つの感情要素例}
  \label{fig:result_comparison}
\end{figure}

\subsection{ABSAタスクの分類}
アスペクトベース感情分析（ABSA）のタスクは、抽出対象の構成要素の複雑さに応じて、単一タスクと複合タスクの2つに大別され、抽出対象の4要素の組み合わせによって表\ref{tab:absa_tasks}のように分類される。
なお、本節では各要素を以下のように表記する。


アスペクト用語: $a$,アスペクトカテゴリー: $c$, 意見用語: $o$, 感情極性: $p$

\begin{table}[htbp]
    \centering
    \caption{ABSAタスクの分類と抽出対象}
    \label{tab:absa_tasks}
    \renewcommand{\arraystretch}{1.3} % 行間を広げて読みやすく
    \small
    \begin{tabular}{l l l p{6.5cm}}
        \hline
        \textbf{分類} & \textbf{タスク名} & \textbf{抽出対象} & \textbf{概要} \\
        \hline
        \hline
        \multirow{3}{*}{単一} 
         & ATE & $\{a\}$ & 文中のアスペクト項を抽出 \\
         & ACD & $\{c\}$ & アスペクトカテゴリを特定 \\
         & ASC & $\{p\}$ & 特定対象に対する感情極性を予測 \\
        \hline
        \rowcolor[gray]{0.9}
        \multirow{5}{*}{複合} 
         & \textbf{ACSA} & $\mathbf{(c, p)}$ & \textbf{カテゴリと感情のペアを抽出（本研究の対象）}\\
         & E2E-ABSA & $(a, p)$ & アスペクト項と感情極性のペアを抽出 \\
         & AOPE & $(a, o)$ & アスペクト項と意見項を抽出 \\
         & ASTE & $(a, o, p)$ & アスペクトカテゴリを除く3要素を抽出 \\
         & ASQP & $(c, a, o, p)$ & 4要素すべてを扱う最も完全なタスク \\
        \hline
    \end{tabular}
\end{table}

\subsection{アスペクトカテゴリ感情分析 (ACSA)}
本研究で扱うアスペクトカテゴリ感情分析 (ACSA)は，入力文に対して「アスペクトカテゴリ ($c$)」と「感情極性 ($p$)」のペア $(c, p)$ を抽出する複合タスクである．

ACSAの最大の特徴は，文中に評価対象を示す具体的な単語（アスペクト語）が存在しない場合でも分析が可能である点である．ユーザ生成のレビュー文においては主語が欠落または、含まれていない文も多く存在する。たとえば、「このレストランは高すぎる」というレビュー文には，「価格」という単語は含まれていないが，ACSAでは「価格 」カテゴリに対するネガティブな評価として検出することが求められる \cite{survey}．
このように，ACSAは文中に含まれる暗示的な意見を扱う上で実用性が高く，レビュー分析において重要な役割を果たす．

\section{使用する言語モデル}

\subsection{T5}
T5（Text-to-Text Transfer Transformer）\cite{t5} は，2019 年に Google が提案した自然言語処理モデルであり，機械翻訳，文書要約，質問応答，文書分類など多岐にわたるタスクにおいて，当時の最高性能（SOTA）を達成した．T5は，BERTのようなエンコーダのみのモデルやGPTのようなデコーダのみのモデルとは異なり，Transformer のエンコーダ・デコーダ構成を採用している．その最大の特徴は，あらゆる自然言語処理タスクを「入力テキストを出力テキストに変換する（Text-to-Text）」問題として統一的に扱う点にある．

T5 は，C4（Colossal Clean Crawled Corpus）と呼ばれる大規模なクリーニング済みウェブテキストデータセットを用いて事前学習されている．事前学習タスクとしては，BERT の MLM に似た「スパン破損（Span-corruption）」と呼ばれるタスクが採用されている．これは，入力文中の連続するトークン列（スパン）をランダムにマスクし，デコーダ側でそのマスクされた部分の文字列を生成・復元させるタスクである．これにより，モデルは文脈理解能力とテキスト生成能力を同時に学習することができる．

そして，事前学習した T5 を特定のタスクに適応させるためのファインチューニングにおいても，この Text-to-Text の枠組みが一貫して適用される．BERT のように下流タスクに応じて出力層（分類ヘッドなど）を追加・変更する必要はなく，すべてのタスクで同一のモデル構造と損失関数を使用する．例えば，文書分類タスクであっても，クラスラベルのIDを出力するのではなく，「positive」や「negative」といったラベルのテキストそのものを生成させることで分類を行う．この統一的なアプローチにより，多様なタスクに対して効率的に転移学習を行うことが可能となっている．

本研究では、sonoisa氏が公開しているT5モデルである、Wikipediaの日本語ダンプデータ、OSCAR、CC-100の日本語コーパス（約100GB）を用いて事前学習を行ったT5-base-ver1.1アーキテクチャのモデル\cite{t5}を使用した。

\subsection{gpt-oss-20B}
gpt-oss-20b\cite{gpt-oss}は，2025年8月に OpenAI が公開したオープンウェイトの推論モデルであり ，高度な推論能力を備えている ．本モデルは，GPT-2およびGPT-3のアーキテクチャに基づいた自己回帰的な Mixture-of-Experts（MoE）トランスフォーマーであり ，総パラメータ数は約20Bである．MXFP4形式への量子化により重みを 4.25ビットで表現することで，メモリ使用量を削減し，16GBのメモリを持つシステムでも動作可能という特徴がある ．

事前学習には，STEMやコーディング，一般知識に焦点を当てた数兆トークンのテキストデータが用いられており ，化学・生物・放射性物質・核などの有害なコンテンツのフィルタリングも行われている ．事前学習後には，OpenAIo3と同様の思考の連鎖（Chain-of-Thought）を用いた強化学習によってポストトレーニングが行われ，推論能力やツール利用能力が強化されている ．

また，システムプロンプトで「low」「medium」「high」の推論レベルを指定することで，タスクに応じた推論の深さを調整できる機能を有している ．

\section{CoT（chain of thought）}
CoT（Chain-of-Thought Prompting）\cite{CoT}は，2022 年に Google の Wei らによって提案されたプロンプトエンジニアリングの手法であり，算術推論や常識推論，記号推論など，多段階の推論を必要とする複雑なタスクにおいて，大規模言語モデル（LLM）の性能を飛躍的に向上させることが示されている．CoT は，従来の入力に対して直接的な回答のみを求める標準的なプロンプティングとは異なり，最終的な回答に至るまでの中間的な推論ステップと呼ばれる一連の思考過程をモデルに生成させるという特徴がある．

CoTは，主にFew-shotプロンプティングの枠組みで用いられ，モデルに与える数ショットの例示の中に，質問と回答のペアだけでなく，その回答を導き出すための論理的な思考プロセス（中間的な推論ステップ）を自然言語で記述して含める．これにより，モデルは提示された思考パターンを模倣し，未知の入力に対しても問題を段階的に分解して解くことができるようになる．

\section{Fine-tune-CoT}
Fine-tune-CoT\cite{Fine-turn-CoT}は、KAISTの研究者らによって提案された、大規模言語モデル（LLM）の推論能力を小型モデルに継承させるための学習手法である。従来、複雑な問題を段階的に解く「Chain-of-Thought（CoT）推論」は、パラメータ数が100Bを超える巨大なモデルでのみ発現する創発的能力と考えられてきた。Fine-tune-CoTは、巨大なモデルを「教師」として利用し、そこから得られた推論過程を「生徒」である小型モデルに学習させることで、このモデル規模の制約を打破し、小規模パラメータモデルでも高度な推論を可能にすることを目的としている。

この手法のプロセスは、大きく分けて「推論生成」「精査（キュレーション）」「ファインチューニング」の3つのステップで構成される。まず、GPT-3などの巨大な教師モデルに対し、Zero-shot-CoTプロンプトを用いて、特定の問題に対する中間的な推論ステップと回答を生成させる。次に、教師モデルが導き出した回答が正解と一致するものだけをフィルタリングし、「問題」を入力、「推論過程＋回答」を出力とする学習用データセットを作成する。これにより、生徒モデルは単に答えを予測するだけでなく、論理的な思考プロセスそのものを模倣するように学習することができる。

Fine-tune-CoTは、巨大モデルへの依存を減らし、実社会のアプリケーションにおいて効率的かつ解釈可能な推論モデルを展開するための重要な道筋を示している

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{関連研究}
本章では，既存手法の説明と本研究の新規性について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{日本語データでのアスペクトベース感情分析における従来手法}
日本語のABSA、特に本研究でも使用する「楽天トラベルレビューデータセット」\cite{rakuten}を用いた研究としては、西元ら による取り組み\cite{nishimoto2025}が挙げられる。彼らは、BERTをベースとした複数の小分類器（Entity ClassifierとAttribute Classifier）を用意し、それらを統合（メタモデル化）することでアスペクトカテゴリと感情極性をラベルとして14カテゴリ分類する手法（Mpm+Tの改良版）を提案している 。
このような従来の分類（Classification）ベースの手法は、感情分析を「事前に定義されたクラスへの割り当て問題」として扱う。しかし、このアプローチには、ラベル（カテゴリ名や感情極性）が持つ意味情報（Semantics）をモデルが十分に活用できないという課題がある 。また、パイプライン的に複数のモデルを組み合わせる手法は、エラー伝搬のリスクやモデル構成の複雑化を招く可能性がある。
本研究では、よりシンプルで汎用的な単一モデルによる解決を目指し、「テキスト生成（Generation）」として定式化することで、単一のモデルでシンプルかつ高精度な分析を目指す。

\section{生成型アスペクトベース感情分析の進展}
近年、事前学習済み言語モデルの発展に伴い、ABSAタスクをテキスト生成問題として解く生成型アプローチが注目されている。
Zhangら は、T5モデル を用いた統一的な生成フレームワークである **GAS (Generative Aspect-based Sentiment Analysis)** を提案した\cite{gas} 。GASでは、ABSAのタスクをSequence-to-Sequenceの形式に変換し、入力文に対して目的とする感情要素（アスペクト語や感情極性など）を自然言語のテキストとして直接生成させる。特に彼らが提案した「抽出形式 (Extraction-style)」 は、`(アスペクト, 感情)` のようなペアを直接出力系列として学習させることで、従来の分類手法を上回る性能を示した 。

本研究は、このZhangらの生成型アプローチを基礎としている。しかし、GASはあくまで最終的な「答え」を直接生成するものであり、なぜその結論に至ったかという「思考のプロセス」はブラックボックスのままである。
本研究の独自性は、この生成プロセスに 推論過程 (Chain of Thought)を明示的に導入する点にある。特に、文脈中にアスペクト語が明示されない暗示的な意見（Implicit Opinion）に対して、論理的な推論ステップを挟むことで、生成モデルの解釈能力と予測精度のさらなる向上を図る。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{予備実験：T5モデルによるベースライン検証}
\label{chap:preliminary_experiment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，提案手法の導入に先立ち，日本語データを用いたT5モデルでの直接生成手法（GASフレームワーク）の基本性能を確認するための予備実験について述べる．

\section{実験目的}
Zhangら \cite{gas} は，英語データセットを用いたABSAにおいて，T5モデルを用いた統一的な生成フレームワークであるGAS (Generative Aspect-based Sentiment Analysis) の有効性を示した．
しかし，日本語のアスペクトカテゴリ感情分析タスクにおけるGASの適用事例や，その有効性は十分に検証されていない．
そこで本予備実験では，日本語の楽天トラベルレビューデータセットを用い，GASフレームワークを適用した場合のベースライン精度を明らかにする．この結果を、本研究における提案手法のベースラインとする。
あわせて，レビュー文を入力とする際に，対象文のみを与える場合と，前の文脈情報（Context）を含める場合とで精度にどのような差異が生じるかを検証する．

\section{実験設定}

\subsection{データセットと前処理}
本研究では，楽天グループ株式会社が国立情報学研究所（NII）を通じて提供している「楽天トラベルレビュー：アスペクト・センチメントタグ付きコーパス」\cite{rakuten} を使用した．
本コーパスは，約12,476件のレビューから文単位に分割された約76,000件のレビュー文に対し，以下の7種類のアスペクトカテゴリと，それぞれの感情極性（ポジティブ・ネガティブ）が付与されたマルチラベルデータセットである．

\begin{itemize}
    \item \textbf{アスペクトカテゴリ}: 朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋
    \item \textbf{感情極性}: ポジティブ ($1$)，ネガティブ ($0$)
\end{itemize}

データセットのアノテーション例を表\ref{tab:dataset_example}に示す。

\begin{table}[!ht]
    \centering
    \caption{楽天トラベルレビューデータセットのアノテーション例}
    \label{tab:dataset_example}
    \small
    \begin{tabular}{p{9.0cm} p{5.0cm}}
        \toprule
        \textbf{レビュー文} & \textbf{正解ラベル} \\
        \midrule
        立地はいいと思いますが、トイレにはこばえが数匹いて、朝御飯の味噌汁なんかは具なしでした。 & 
        立地: ポジティブ \newline
        設備・アメニティ: ネガティブ \newline
        朝食: ネガティブ \\
        \bottomrule
    \end{tabular}
\end{table}

本実験では，全データ（76,624文）に対し、データの質を担保するために以下の基準に基づくフィルタリングを行った．

\begin{itemize}
    \item \textbf{言語および品質による除外}
    
    日本語以外の言語で記述されたデータ、および判読不能なノイズを含むデータを除外した。
    
    \item \textbf{モデル制約による除外}
    
    日本語T5モデルの最大入力長（512トークン）を考慮し、トークナイザによる処理後のトークン数が500を超える長文データを除外した。
    
    \item \textbf{タスク設定による除外}
    
    定義された7つのアスペクトカテゴリのいずれにも該当しない（None）データ、および同一カテゴリに対して相反する感情極性が同時に付与されている矛盾したデータを除外した。
    
    \item \textbf{重複排除}
    
    評価の厳密性を保つため、内容が完全に一致する重複データを除外し、ユニークな事例のみを保持した。
\end{itemize}

上記の前処理を経た有効データは50,406件であった。
本データセットはカテゴリごとのデータ数に偏りがあるため、学習時のバイアスを軽減する目的でダウンサンプリングを行った。
具体的には、可能な限り各カテゴリの分布が均一になるよう調整しつつ、最終的に学習データ20,000件，検証データ2,000件，評価用テストデータ2,000件を抽出した。


\subsection{生成タスクへの変換（ラベル形式）}
本研究では分類問題を「テキスト生成問題」として扱うため，Zhangら \cite{gas} の抽出形式（Extraction-style）を参考に，教師データのラベル形式を変換した．
具体的には，出力ターゲットを「\texttt{カテゴリ:感情極性}」の形式とし，複数の意見が含まれる場合は垂直バー「\texttt{|}」で連結する形式を採用した．
変換例を表\ref{tab:label_example}に示す．

\begin{table}[h]
    \centering
    \caption{生成タスクにおける入出力データの例}
    \label{tab:label_example}
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{p{2.0cm} p{11.0cm}}
        \toprule
        \textbf{項目} & \textbf{内容} \\ 
        \midrule
        \textbf{入力文} & 立地はいいと思いますが、トイレにはこばえが数匹いて、朝御飯の味噌汁なんかは具なしでした。 \\ 
        \midrule
        \textbf{出力ラベル} & 立地:ポジティブ \textbar\ 設備・アメニティ:ネガティブ \textbar\ 朝食:ネガティブ \\ 
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{出力の正規化処理}
生成モデルは自由なテキストを出力するため，出力されたアスペクトカテゴリ名に微細な誤字や表記ゆれが含まれる可能性がある．
例えば，「サービス」を「サービ」と出力した場合，これを単純な不一致として扱うとモデルの本来の性能を過小評価する恐れがある．

そこで本実験では，先行研究を参考にモデルの出力した各用語に対し，レーベンシュタイン距離（編集距離）を用いた正規化処理を適用した．

レーベンシュタイン距離とは、一方の文字列をもう一方の文字列に変形させるために必要な「挿入」「削除」「置換」の最小操作回数を定義したものである。
\begin{itemize}
    \item \textbf{挿入: 文字を追加する（例：「サービ」 $\rightarrow$ 「サービ\textbf{ス}」）}
    \item \textbf{削除: 文字を取り除く（例：「サービス\textbf{ッ}」 $\rightarrow$ 「サービス」）}
    \item \textbf{置換: 文字を書き換える（例：「サービ\textbf{ズ}」 $\rightarrow$ 「サービ\textbf{ス}」）}
\end{itemize}


具体的には，出力された単語が事前に定義されたアスペクトカテゴリ集合 $V$（朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋）に含まれない場合，以下の手順で補正を行う．

\begin{enumerate}
    \item 出力語と語彙集合 $V$ 内の各単語との編集距離 $d$ を計算する．
    \item 最も距離が小さい単語を候補とし，その最小距離が $2$ 以下，かつ出力語の長さの半分以下である場合に限り，当該語彙への置き換えを行う．
    \item 上記の条件を満たさない場合は，抽出失敗（None）として扱う．
\end{enumerate}

この後処理により，生成モデル特有の軽微な文字生成ミスを許容し，本質的な感情分析性能を評価する．

\subsection{モデルおよび学習設定}
本実験におけるモデルの選定および学習時のハイパーパラメータの設定について述べる。

\subsubsection{使用モデル}
本研究では、sonoisa氏が公開しているT5モデルである、\texttt{sonoisa/t5-base-japanese-v1.1}を使用した。このモデルは、T5-baseモデルをWikipediaの日本語ダンプデータ、OSCAR、CC-100の日本語コーパスなど約100GBの日本語テキストデータを用いて日本語事前学習を行ったモデルである。

\subsubsection{ハイパーパラメータと学習条件}
モデルの学習における主要な設定値を表\ref{tab:simple_hyperparameters}に示す。

\begin{table}[htbp]
  \centering
  \caption{学習時におけるハイパーパラメータの設定}
  \label{tab:simple_hyperparameters}
  \begin{tabular}{lc} \hline
    項目 & 設定値 \\ \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 64 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\ \hline
  \end{tabular}
\end{table}

最大入力トークン数および出力トークン数は、計算リソースと対象とするデータセットの平均長を考慮し、それぞれ 128 および 64 に設定した。最適化アルゴリズムには AdamW を採用し、学習率を $1.0 \times 10^{-4}$ として固定した。

学習の効率化および過学習の抑制のため、検証データにおける F1 スコアを監視対象としたアーリーストッピング（Early Stopping）を導入した。具体的には、5 エポック連続で F1 スコアの向上が認められない場合に学習を打ち切るよう設定した。また、各エポック終了時に検証データで最も高い精度を示した時点のモデル重みを、最終的な推論に用いる最良のモデルとして利用した。

また、実験結果の統計的な妥当性を確保するため、シード値として 42、100、1000 の 3 通りを設定し、それぞれの条件で独立した学習および評価を行った。本論文で報告する精度評価値は、これら 3 回の試行によって得られた結果の平均値である。

\subsection{比較手法} 
本研究では、T5モデルへの入力形式がアスペクトカテゴリ感情分類（ACSA）の精度に与える影響を調査するため、以下の2種類の手法を比較・検証する。第一に、評価対象となるレビュー文のみを入力とする手法（以下、Simple手法）、第二に、対象文にその直前の文脈情報を付加して入力する手法（以下、Simple-context手法）である。

本研究における文脈情報とは、楽天トラベルデータセットにおいて、一つのレビューが文単位で分割・管理されている点を利用し、評価対象文の直前（一つ前のID）に位置する文と定義した。評価対象文がレビューの冒頭である場合など、直前の文が存在しない場合には、文脈情報を「なし」と定義している。文脈情報として複数の文を遡って付与する構成も検討したが、本研究ではT5モデルの最大入力トークン数制限を考慮し、直近の1文のみを採用した。

宿泊レビュー等のユーザー生成コンテンツにおいて、評価対象文は必ずしも一文で意味が完結しているとは限らない。特に、代名詞の指示対象（照応）や、前の文脈に依存した評価対象の省略を正確に把握する必要がある。そこでSimple-context手法では、対象文を\texttt{<}本文\texttt{>}、その直前の文を\texttt{<}文脈文\texttt{>}という特殊タグを用いて構造化し、モデルに明示的に入力する形式を採用した。これにより、モデルが分析対象の範囲を厳密に認識しつつ、周囲の文脈から欠落した情報を補完することで、高精度な判定が可能になると考えられる。

%表\ref{tab:Simple-context_example}に、Simple-context手法における具体的な入出力データの例を示す。本例において、本文の「アメゴの刺身」という記述のみでは、それが朝食と夕食のいずれに対する言及であるかを特定することは困難である。しかし、文脈文に含まれる「夕食」という情報をモデルが参照することで、適切なカテゴリ（夕食）を導出することが可能となる。Simple-context手法は、このような文脈依存性の高いケースにおける分類精度の向上を主眼としている。

\begin{table}[h]
    \centering
    \caption{Simple-context手法における入出力データの例}
    \label{tab:Simple-context_example}
    \renewcommand{\arraystretch}{1.3} % 行間を少し広げて読みやすく
    \begin{tabular}{p{2.5cm} p{10.5cm}}
        \toprule
        \textbf{項目} & \textbf{内容} \\ 
        \midrule
        \textbf{入力テキスト} & \texttt{<}文脈文\texttt{>}囲炉裏を前にした夕食は予想以上に最高。\texttt{<}/文脈文\texttt{>} \newline
        \texttt{<}本文\texttt{>}特に、アメゴの刺身はとても美味しかったです！\texttt{<}/本文\texttt{>} \\ 
        \midrule
        \textbf{出力ラベル} & 夕食:ポジティブ \\ 
        \bottomrule
    \end{tabular}
\end{table}

\subsection{評価指標}
評価方法として、本実験では、正解率(accuracy)、適合率(Precision)、再現率(Recall)、F1値(F1-score)の評価指標を用いて、アスペクトカテゴリ分析結果を評価した。それぞれの評価指標について説明する。
\subsection{評価指標}
本研究におけるアスペクトカテゴリ感情分類（ACSA）の結果を定量的に評価するため、以下の3つの指標を用いる。本タスクは一つの文に対して複数のアスペクトカテゴリおよび感情値のペア（例：部屋：ポジティブ、サービス：ネガティブ）を抽出するマルチラベル分類であるため、正解ラベルの集合とモデルの出力集合を比較することで各指標を算出する。なお、算出にあたっては、以下の3つの要素を定義する。

\begin{itemize}\item \textbf{真陽性 (True Positive: TP)}：モデルが予測したカテゴリと感情のペアが、正解ラベルに存在する場合。\item \textbf{偽陽性 (False Positive: FP)}：モデルが予測したペアが、正解ラベルに存在しない場合（余計な出力）。\item \textbf{偽陰性 (False Negative: FN)}：正解ラベルに含まれるペアを、モデルが予測できなかった場合（見落とし）。
\end{itemize}

\subsubsection{正解率 (Accuracy)}正解率は、全テストデータのうち、モデルの出力したカテゴリおよび感情のペアが、正解ラベルと完全に一致したデータの割合を示す。本研究のようなマルチラベルタスクにおいては、全てのラベルが一致した場合のみを正解とする。全体の分類性能を直感的に把握するために用いるが、一部のカテゴリのみを正解した場合が評価されないため、後述の適合率や再現率と併せて考察する必要がある。

\subsubsection{適合率 (Precision)}適合率は、モデルが「正解」と予測した全ペアのうち、実際に正解ラベルに含まれていたペアの割合を示す。以下の式で定義される。
\[\text{Precision} = \frac{\text {TP}}{\text {TP} + \text {FP}}\]
本指標が高いことは、モデルが「根拠のない誤った評価」や「存在しないカテゴリ」を不必要に出力（ハルシネーション）していないことを意味し、出力結果の信頼性を表す。
\subsubsection{再現率 (Recall)}再現率は、正解ラベルに含まれる全ペアのうち、モデルが正しく予測できたペアの割合を示す。以下の式で定義される。
\[\text{Recall} = \frac{\text {TP}}{\text {TP} + \text {FN}}\]
本指標が高いことは、レビュー文に含まれる多様な評価項目を漏らさず抽出できていることを意味する。

\subsubsection{F1値 (F1-score)}F1値は、適合率と再現率の調和平均であり、以下の式で定義される。
\[F1 = \frac{2 \cdot \text {Precision} \cdot \text {Recall}}{\text {Precision} + \text {Recall}}\]
適合率と再現率はトレードオフの関係にあることが多いため、これらを統合したF1値を用いることで、モデルの総合的な抽出・分類性能を評価する。本研究における各手法の優劣を判断する主要な指標として採用する。

\section{実験結果}
実験結果を表\ref{tab:baseline_overall}および表\ref{tab:baseline_category_f1}に示す．
表\ref{tab:baseline_overall}は先の章で述べた4つの評価指標での比較を示している．また，表\ref{tab:baseline_category_f1}はアスペクトカテゴリごとに分けた際のF1値の比較を示す．
\begin{table}[!ht]
  \centering
  \caption{ベースラインモデルの性能比較（3回の試行による平均 $\pm$ 標準偏差）}
  \label{tab:baseline_overall}
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    Simple    & $0.894 \pm 0.003$ & $0.745 \pm 0.014$ & $0.813 \pm 0.008$ & $0.624 \pm 0.010$ \\
    Simple-context  & $\textbf{0.903} \pm \textbf{0.004}$ & $\textbf{0.760} \pm \textbf{0.005}$ & $\textbf{0.825} \pm \textbf{0.003}$ & $\textbf{0.643} \pm \textbf{0.004}$ \\ \bottomrule
  \end{tabular}
\end{table}

\begin{table}[!ht]
  \centering
  \caption{アスペクトカテゴリごとのF1値の比較}
  \label{tab:baseline_category_f1}
  \begin{tabular}{lcc} \toprule
    アスペクトカテゴリ & Simple (Review-only) & Simple (Context-aware) \\ \midrule
    風呂               & $0.854$ & $\textbf{0.864}$ \\
    夕食               & $\textbf{0.854}$ & $0.845$ \\
    立地               & $0.842$ & $\textbf{0.850}$ \\
    部屋               & $0.818$ & $\textbf{0.830}$ \\
    朝食               & $0.817$ & $\textbf{0.825}$ \\
    設備・アメニティ   & $0.777$ & $\textbf{0.802}$ \\
    \textbf{サービス}  & $0.721$ & $\textbf{0.761}$ \\ \bottomrule
  \end{tabular}
\end{table}

\section{考察と課題}
\subsection{考察：文脈情報の有効性}
実験結果より、文脈情報を付与した Simple (Context-aware) 手法は、レビュー文のみを用いる Simple (Review-only) 手法と比較して、4つの評価指標すべてにおいて上回る結果となった。
特に、総合的な性能を示すF1値では $0.012$ ポイントの向上が確認された。
また、アスペクトカテゴリごとの比較においても、夕食カテゴリを除くほぼすべての項目で精度が向上している。

この結果は、楽天トラベルのようなレビューデータにおいて、代名詞の指示対象（照応）や、文脈に依存して省略された評価対象を正確に捉える上で、前後の文脈情報が一定の有効性を持つことを示唆している。
しかし、その向上幅は限定的であり、単純な文脈の連結だけでは解決できない課題が残されていることも明らかとなった。

\subsection{課題分析}
本実験の結果から明らかになったアスペクトカテゴリ感情分析（ACSA）における課題は、主に以下の2点に集約される。

第一に、\textbf{再現率（Recall）の低さ}である。
両手法ともに、適合率（Precision）が $0.90$ 前後と高い水準にあるのに対し、再現率は $0.75$ 前後と約 $0.15$ ポイントもの乖離が見られた。
これは、モデルが抽出したペアの正答率は高いものの、本来抽出すべきアスペクトと感情極性のペアを数多く見逃している（抽出漏れが多い）ことを意味する。

第二に、\textbf{暗示的なアスペクト表現への対応}である。
カテゴリ別のF1値において、「サービス」カテゴリのスコアが他と比較して顕著に低い結果となった。
エラー分析の結果、「サービス」に関する評価は、「朝食」や「部屋」のように具体的な単語が明示されることが少なく、「待たされた」「気が利かない」といった文脈から読み取る必要がある**暗示的（Implicit）な表現**が大半を占めることが分かった。
従来の単純な生成モデルでは、このような表層的な単語マッチングに依存しない表現を十分に捉えきれていないと考えられる。

\subsection{次章への展望}
上記の問題を解決するためには、人間が無意識に行っている「待たされた $\rightarrow$ 対応が遅い $\rightarrow$ サービス:ネガティブ」といった論理的な推論ステップをモデルに学習させる必要がある。

そこで次章では、T5モデルにACSAの中間推論プロセス（Chain of Thought）を出力させる提案手法について述べる。
推論過程を明示的に扱わせることで、文中に含まれる暗示的なアスペクトカテゴリの抽出能力を向上させ、抽出漏れ（Recallの低さ）の改善を目指す。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{提案手法：Fine-tune-CoTによる推論過程の導入}
\label{chap:proposed_method}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，前章で明らかになった課題（再現率の低さおよび暗示的アスペクトの抽出漏れ）を解決するための提案手法について述べる．

\section{手法の概要 (Fine-tune-CoT)}
\label{sec:finetunecot_overview}

\subsection{Fine-tune-CoTのアプローチ}
本研究では，ACSAタスクにおいて中間推論プロセス（Chain of Thought: CoT）をモデルに学習させるため，Hoら \cite{Fine-turn-CoT} が提案した \textbf{Fine-tune-CoT} の枠組みを採用する．
Fine-tune-CoTは，大規模言語モデル（LLM）が持つ高度な推論能力を，蒸留（Distillation）のアプローチによって小規模モデルに継承させる手法である．

本手法のプロセスは，以下の3つのステップで構成される（図参照）．

\begin{enumerate}
    \item \textbf{推論生成 (Reasoning Generation)}:
    高度な推論能力を持つ教師モデル（本研究では [具体的なモデル名] を使用）に対し，入力文と特定のプロンプトを与え，中間的な推論ステップを含む回答を生成させる．
    
    \item \textbf{精査 (Curation)}:
    教師モデルが生成したデータのうち，最終的な回答が正解ラベルと完全に一致するもののみをフィルタリングする．これにより，誤った推論を含むノイズデータを除外し，高品質な「入力 $\rightarrow$ 推論過程 $\rightarrow$ 回答」のペアを作成する（以下，CoTデータセット）．
    
    \item \textbf{ファインチューニング (Fine-tuning)}:
    作成したCoTデータセットを用いて，生徒モデル（T5）を学習させる．これにより，生徒モデルは単に答えを予測するだけでなく，教師モデルの論理的な思考プロセスそのものを模倣するように学習する．
\end{enumerate}

\subsection{構造化された推論形式の採用}
一般的なCoT（Zero-shot-CoTなど）では「Step-by-stepで考えて」といった指示により多様な自然言語による推論を生成させる．
しかし，本研究で用いるT5のような小規模モデルにとって，自由度の高すぎる推論テキストは学習のノイズとなり，収束を妨げる可能性がある．
T5モデルはSequence-to-Sequence形式の構造変換を得意とする特性があるため，本研究では自由記述ではなく，\textbf{厳密に定義・構造化された推論形式}を採用する．
具体的には，次節で述べる2つの推論パターンを教師モデルに強制してデータを生成し，その有効性を検証する．


----Fine-turn-CoTの図-----


\section{中間推論の形式設計}
\label{sec:reasoning_formats}

本研究では，アスペクトカテゴリ感情分析に適した推論プロセスとして，設計思想の異なる以下の2つの形式を考案した．

\subsection{パターン1：用語起点型 (Term-Oriented Inference)}
用語起点型は，従来のABSAタスクの処理フロー（用語抽出 $\rightarrow$ 分類）をCoTとして言語化した形式である．
文中に明示されている評価対象語（アスペクト語）を起点として推論を展開するため，アスペクト語が明確なケースにおいて高い適合率が期待できる．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 用語抽出] 文中から評価対象となっている語句をすべて抽出する．
        \item[STEP2 カテゴリ分類] 抽出した各用語が，7つの定義済みカテゴリのどれに該当するかを分類する．
        \item[STEP3 感情分析] カテゴリごとに，対応する用語周辺の表現から極性を判定する．
        \item[STEP4 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応。\\
\textbf{CoT出力}:\\
\texttt{<STEP1> レストランスタッフ | 対応}\\
\texttt{<STEP2> レストランスタッフ $\rightarrow$ サービス | 対応 $\rightarrow$ サービス}\\
\texttt{<STEP3> サービス $\rightarrow$ 一番よかった $\rightarrow$ ポジティブ}\\
\texttt{<STEP4> サービス:ポジティブ}
\end{minipage}}

\subsection{パターン2：カテゴリ点検型 (Category-Scanning Inference)}
カテゴリ点検型は，第4章で課題となった「抽出漏れ（Recallの低さ）」と「暗示的アスペクト」に対応するための形式である．
文中の単語に依存せず，事前に定義された7つのカテゴリすべてについて「言及があるか？」を順次確認（スキャン）する検品ロジックを採用している．これにより，具体的なアスペクト語が存在しない場合でも，文脈からの推論を促すことを狙いとしている．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 全カテゴリ点検] 7つのカテゴリすべてに対し，有無とその根拠（該当箇所または文脈）を列挙する．
        \item[STEP2 感情分析] 「あり」と判定されたカテゴリについてのみ，感情極性を判定する．
        \item[STEP3 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応。\\
\textbf{CoT出力}:\\
\texttt{<STEP1>}\\
\texttt{- サービス: あり (根拠: レストランスタッフさんの対応)}\\
\texttt{- 夕食: なし}\\
\texttt{- 朝食: なし}\\
\texttt{- 立地: なし}\\
\dots （中略） \dots\\
\texttt{<STEP2>}\\
\texttt{- サービス: レストランスタッフさんの対応 $\rightarrow$ ポジティブ}\\
\texttt{<STEP3> サービス:ポジティブ}
\end{minipage}}

\section{CoTデータの生成方法}
\label{sec:cot_generation}

本研究では，教師モデルの知識蒸留により，学習用データセット（楽天トラベルレビューデータセットの学習分割）に対して中間推論付きの拡張データセットを作成した．
具体的な手順は以下の通りである．

\subsection{プロンプトによる推論生成}
まず，教師モデル（gpt-oss-20B\cite{gpt-oss}）に対し，元のレビュー文 $x$ と共に，中間推論の生成を促すプロンプト $P$ を入力した．
プロンプトには，タスクの定義，出力フォーマットの指定，および数件のFew-shot事例（入力と理想的なCoT出力のペア）を含めた．
これにより，教師モデルは入力文 $x$ に対し，推論過程 $r$ と最終回答 $y$ を含む系列 $\hat{z} = (r, y)$ を生成する．

\subsection{データの精査（キュレーション）}
教師モデルは常に正しい推論を行うとは限らない．誤った推論や回答を含むデータを生徒モデルに学習させることは，性能低下（ハルシネーションの増大）につながるリスクがある．
そこで，生成されたデータに対して以下のフィルタリング処理を行った．

\begin{enumerate}
    \item \textbf{回答の一致確認}: 
    教師モデルが生成した最終回答 $y$ が，元のデータセットの正解ラベル $y_{gold}$ と完全に一致するかを確認する．
    \item \textbf{形式の整合性確認}: 
    生成された推論過程 $r$ が，指定したフォーマット（\texttt{<}STEP\texttt{>}タグや順序）を遵守しているかを確認する．
\end{enumerate}

上記の条件を満たしたデータのみを学習用データとして採用し，条件を満たさないデータは破棄，または再度生成を行った．
最終的に構築されたCoTデータセット $D_{CoT}$ は，入力文 $x$ と，精査済みの推論付きラベル $z = (r, y_{gold})$ のペアで構成される．

\subsection{損失計算について}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{評価実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{実験目的}
本実験では、日本語の楽天トラベルレビューデータセットを用い、3つの手法の精度を比較する。3つの手法とは、第4章で行った予備実験において最も高精度だったsimple-context手法、提案手法である中間推論を学習させる用語起点型、カテゴリ点検型である。simple-context手法をベースラインとして、CoTデータとしてモデルに推論過程を明示的に扱わせることで、文中に含まれる暗示的なアスペクトカテゴリの抽出能力を向上させ、精度の比較を行う。

\section{実験設定}
CoTデータのハイパーパラメータを表\ref{tab:CoT_hyperparameters}に示す。そのほかデータセット、評価指標、学習条件の設定などは第4章と同様である。
学習戦略としてのモデルに対して「中間推論」と「最終的な回答」のどちらを優先すべきかのトレードオフを探索においてαを0.2, 0.5, 0.8の3値で比較を行う。

\begin{table}[htbp]
  \centering
  \caption{CoTデータにおける学習時のハイパーパラメータ}
  \label{tab:CoT_hyperparameters}
  \begin{tabular}{lc} \hline
    項目 & 設定値 \\ \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 400 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\ \hline
  \end{tabular}
\end{table}

\section{実験結果}
本実験における全体性能の比較を表\ref{tab:proposal_overall}に，アスペクトカテゴリごとのF1スコアの比較を表\ref{tab:proposal_category_f1}に示す．
\subsection{全体性能の比較}
各手法における最良の設定（Term-Oriented: $\alpha=0.5$, Category-Scanning: Normal）での比較結果を表\ref{tab:best_model_comparison}に示す．
表より，提案手法であるCategory-Scanning (Pattern 2) は，F1スコアにおいて $0.863$ を達成し，ベースライン（Simple Context-aware）を大きく上回る性能を示した．
特にRecall（再現率）においては，$0.760$ から $0.835$ へと劇的な向上が見られ，抽出漏れの改善に大きく寄与していることが確認できる．

\begin{table}[tb]
  \centering
  \caption{提案手法とベースラインの性能比較（各手法の最良パラメータにおける平均 $\pm$ 標準偏差）}
  \label{tab:best_model_comparison}
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    Simple-Context & $\textbf{0.903} \pm 0.004$ & $0.760 \pm 0.005$ & $0.825 \pm 0.003$ & $0.643 \pm 0.004$ \\
    用語起点型CoT ($\alpha=0.5$) & $0.856 \pm 0.002$ & $0.810 \pm 0.009$ & $0.832 \pm 0.005$ & $0.653 \pm 0.003$ \\
    \textbf{カテゴリ点検型CoT(Normal)} & $0.893 \pm 0.004$ & $\textbf{0.835} \pm \textbf{0.006}$ & $\textbf{0.863} \pm \textbf{0.002}$ & $\textbf{0.700} \pm \textbf{0.001}$ \\ \bottomrule
  \end{tabular}
\end{table}

\subsection{アスペクトカテゴリごとの詳細分析}
アスペクトカテゴリごとのF1スコアの比較を表\ref{tab:best_category_comparison}に示す．
Category-Scanning手法は，「夕食」「風呂」などの明示的なカテゴリだけでなく，従来手法が苦手としていた「サービス」カテゴリにおいても $0.836$ という高いスコアを記録している．
これは，Term-Oriented手法（$0.751$）やベースライン（$0.761$）と比較しても顕著な改善であり，カテゴリ点検型の推論プロセスが暗示的なアスペクト表現の抽出に有効であることを示唆している．

\begin{table}[!ht]
  \centering
  \caption{アスペクトカテゴリごとのF1値比較（最良モデル）}
  \label{tab:best_category_comparison}
  \begin{tabular}{lccc} \toprule
    カテゴリ & Simple (Context) & 用語起点型CoT ($\alpha=0.5$) & \textbf{用語起点型CoT} \\ \midrule
    夕食              & $0.845$ & $0.878$ & $\textbf{0.902}$ \\
    風呂              & $0.864$ & $0.879$ & $\textbf{0.897}$ \\
    立地              & $0.850$ & $0.858$ & $\textbf{0.886}$ \\
    朝食              & $0.825$ & $0.849$ & $\textbf{0.871}$ \\
    部屋              & $0.830$ & $0.826$ & $\textbf{0.851}$ \\
    \textbf{サービス} & $0.761$ & $0.751$ & $\textbf{0.836}$ \\
    設備・アメニティ  & $0.802$ & $0.780$ & $\textbf{0.794}$ \\ \bottomrule
  \end{tabular}
\end{table}


\section{分析・考察}
\subsection{定量分析}
\subsubsection{手法ごとの精度比較}
表\ref{best_model_comparison}に示す通り、Simple-context手法、用語起点型CoT手法、カテゴリ点検型CoT手法の3手法を比較すると、提案手法であるカテゴリ点検型CoTがF1-scoreおよびAccuracyにおいて他手法を大きく上回る性能を示した。
特筆すべきは、CoTの導入目的の一つである再現率（Recall）の向上である。
カテゴリ点検型は、ベースラインと比較してRecallが $0.075$ ポイントと大幅に上昇しており、この抽出漏れの改善がF1値と正解率の向上に直接的に寄与したと考えられる。
一方で、用語起点型CoTもベースライン比でRecallが $0.05$ ポイント上昇しているものの、その代償として適合率（Precision）が $0.047$ ポイント低下するトレードオフが発生している。その結果、最終的なF1値と正解率は微増に留まった。
これに対し、カテゴリ点検型は適合率の低下を最小限（ベースラインと同等水準）に抑えつつ、再現率のみを大幅に引き上げることに成功しており、極めて理想的な精度向上を達成している。

次に、表\ref{best_category_comparison}を用いてアスペクトカテゴリごとの詳細を分析する。
カテゴリ点検型CoT手法は、「設備・アメニティ」を除くすべてのカテゴリにおいてベースラインを上回るF1値を記録した。
特に、課題とされていた「サービス」カテゴリにおいては $0.836$ という高いスコアを達成している。これは、ベースラインと比較して顕著な改善であり、カテゴリ点検型の推論プロセスが、用語が欠落した暗示的なアスペクト表現の抽出に有効であることを強く示唆している。
また、その他の明示的なカテゴリにおいても安定した向上が確認されたことから、本手法は表現の形式（明示・暗示）にかかわらず、アスペクトの見逃しを包括的に削減可能であるといえる。

\subsubsection{学習戦略による精度比較}
図\ref{fig:alpha_sensitivity}に、損失計算の重みパラメータ $\alpha$ の違いによる精度の推移を示す。
結果として、損失関数の重み付けによる精度の改善効果は限定的であることが明らかとなった。
用語起点型CoTでは $\alpha=0.5$ の設定でF1値が最大となったが、Normal設定（重み付けなし）との差は微小である。
一方、カテゴリ点検型CoTにおいては、従来の損失計算手法（Normal）が最も高い精度を示し、次点で $\alpha=0.2$ （中間推論重視）の設定が続いた。
特筆すべきは、$\alpha$ を大きく設定し、モデルに「回答（ラベル）」の生成を重視させるほど、逆に精度が低下している点である。
この傾向は、正しい最終回答を導き出すためには、その過程である「中間推論」の生成を軽視してはならず、推論プロセスを十分に学習させることが不可欠であることを裏付けている。
したがって、カテゴリ点検型においては、人為的な重み付けを行うよりも、モデルが自然に推論と回答を学習する（Normal）設定が、点検ロジックの特性を最も活かせる設定であると結論付けられる。

\subsection{定性分析}
\subsubsection{暗示的アスペクトの抽出成功事例}
表\ref{tab:qualitative_case_study}に、本実験における各手法の出力結果の一例を示す。
本事例の入力文には、「スタッフ」などの「サービス」カテゴリを直接示唆する明示的なアスペクト語が存在しない。

その結果、\textbf{Simple手法}では、「夕食」は抽出できたものの、文脈に含まれない「朝食」を誤って出力（Hallucination）し、かつ肝心の「サービス」カテゴリに関しては抽出漏れ（Missed）が発生している。

また、\textbf{用語起点型CoT}においては、「バイキング」という単語から「夕食」への分類は成功しているが、「会場」や「待たされた」という記述を物理的な設備への不満と解釈し、「設備・アメニティ」カテゴリへの誤分類を起こしている。

対して、提案手法である\textbf{カテゴリ点検型CoT}は、STEP1の点検プロセスにおいて、「10分以上待ちました」という事象を根拠として「サービス」カテゴリへ正しく対応付けている。
これは、単語の表面的な情報のみに依存せず、「待たされる $\rightarrow$ サービスの問題」という論理的な推論が正常に機能した結果であり、暗示的な表現に対するカテゴリ点検型の優位性を強く裏付けるものである。
\begin{table}[tb]
    \centering
    \caption{暗示的表現を含む事例における推論プロセスの比較}
    \label{tab:qualitative_case_study}
    \renewcommand{\arraystretch}{1.2} % 行間調整
    \footnotesize % 文字サイズを少し小さくして収まりを良くする
    % 列幅を調整 (合計がtextwidthを超えないように注意)
    \begin{tabular}{|p{2.5cm}|p{12.0cm}|}
        \hline
        \multicolumn{2}{|c|}{\textbf{事例情報}} \\
        \hline
        \textbf{入力文} & \texttt{<文脈文>}一番の問題は、食事です。（特に夕食）\texttt{</文脈文>} \newline \texttt{<本文>}まず、バイキングの会場に入るまでに10分以上待ちました。\texttt{</本文>} \\
        \hline
        \textbf{正解ラベル} & \textbf{サービス:ネガティブ} \textbar\ 夕食:ネガティブ \\
        \hline
        \hline
        \multicolumn{2}{|c|}{\textbf{モデル出力の比較}} \\
        \hline
        \textbf{Simple} \newline (Context-aware) & 夕食:ネガティブ \textbar\ 朝食:ネガティブ \newline 
        $\rightarrow$ \textcolor{red}{$\times$ 「サービス」の抽出漏れ（Missed）および「朝食」の誤検知} \\
        \hline
        \textbf{Term-Oriented} \newline (用語起点型) & 
        \texttt{<STEP1>} バイキング \textbar\ 会場 \textbar\ 10分以上待ちました \newline
        \texttt{<STEP2>} バイキング$\rightarrow$夕食 \textbar\ 会場$\rightarrow$設備・アメニティ \textbar\ 10分以上待ちました$\rightarrow$設備・アメニティ \newline
        \texttt{<STEP3>} 夕食$\rightarrow$10分以上待ちました$\rightarrow$ネガティブ \textbar\ 設備・アメニティ$\rightarrow$10分以上待ちました$\rightarrow$ネガティブ \newline
        \texttt{<STEP4>} 夕食:ネガティブ \textbar\ \textbf{設備・アメニティ:ネガティブ} \newline
        $\rightarrow$ \textcolor{red}{$\times$ 「会場」を用語ベースで推論し、設備への不満と誤認} \\
        \hline
        \textbf{Category-Scanning} \newline (カテゴリ点検型) & 
        \texttt{<STEP1>} \newline
        - \textbf{サービス:あり(根拠:10分以上待ちました)} \newline
        - 夕食:あり(根拠:バイキングの会場に入るまでに10分以上待ちました) \newline
        - 朝食:なし \newline
        - 立地:なし \newline
        - 設備・アメニティ:なし \newline
        - 部屋:なし \newline
        - 風呂:なし \newline
        \texttt{<STEP2>} \newline
        - サービス:10分以上待ちました$\rightarrow$ネガティブ \newline
        - 夕食:バイキングの会場に入るまでに10分以上待ちました$\rightarrow$ネガティブ \newline
        \texttt{<STEP3>} \textbf{サービス:ネガティブ \textbar\ 夕食:ネガティブ} \newline
        $\rightarrow$ \textcolor{blue}{$\bigcirc$ 全カテゴリ点検により文脈から「サービス」を抽出成功} \\
        \hline
    \end{tabular}
\end{table}


\subsection{エラー傾向の定量的分析}
表\ref{tab:error_comparison}に、各手法におけるエラータイプ別の発生件数（3試行の平均）を示す。本分析では、特に「抽出漏れ（Aspect Missed）」と「過剰検出（Aspect Hallucination）」の2点に着目し、手法間の特性の違いを考察する。

第一に、本研究の主要な改善目標であった\textbf{抽出漏れ（Missed）}について述べる。
ベースラインであるSimple手法では平均 $413.7$ 件発生していた抽出漏れが、カテゴリ点検型CoTでは $293.3$ 件まで減少しており、約 $30\%$ の大幅な改善が確認された。
用語起点型CoTも $344.7$ 件まで減少させているものの、カテゴリ点検型ほどの改善には至っていない。
これは、全カテゴリを網羅的に走査する「検品ロジック」が、従来の単語依存型アプローチでは取りこぼしていた暗示的な評価表現を効果的に補足できていることを定量的に裏付けている。

第二に、\textbf{過剰検出（Hallucination）}の傾向について分析する。
一般に、抽出漏れを減らそうとモデルの感度を高めると、不必要な箇所まで抽出してしまう過剰検出が増加し、適合率（Precision）が低下するトレードオフの関係にある。
実際に、用語起点型CoTでは過剰検出が $179.3$ 件とベースライン（$145.0$ 件）から大幅に増加しており、これが前述のPrecision低下の主因となっている。
しかし、カテゴリ点検型CoTにおける過剰検出は $144.3$ 件に留まり、ベースラインと同等水準の低い発生率を維持している。

以上の分析から、カテゴリ点検型CoTは、単に「多く抽出する」ことで再現率を高めているのではなく、各カテゴリの有無を論理的に検証することで、\textbf{「正解すべき箇所のみを高い精度で特定し、同時に見落としを最小化する」}という、極めて精度の高い推論プロセスを実現していると結論付けられる。

\begin{table}[tb]
  \centering
  \caption{手法別エラータイプの発生件数比較（3回の平均）}
  \label{tab:error_comparison}
  \small
  \begin{tabular}{lcccc} \toprule
    手法 & Hallucination & Missed & Sentiment Error & Other Error \\ \midrule
    Simple (Context-aware)       & $145.0$ & $413.7$ & $36.7$ & $118.3$ \\
    Term-Oriented ($\alpha=0.5$) & $179.3$ & $344.7$ & $\textbf{33.3}$ & $136.3$ \\
    \textbf{Category-Scanning (Normal)} & $\textbf{144.3}$ & $\textbf{293.3}$ & $40.7$ & $121.3$ \\ \bottomrule
  \end{tabular}
  \footnotesize
  \\ \vspace{1mm}
  ※ Hallucination: 過剰検出（適合率低下の要因）, Missed: 抽出漏れ（再現率低下の要因）
\end{table}

\subsection{考察}
\subsubsection{「抽出」から「検証」へのパラダイムシフトによる再現率の向上}
本研究における最大の成果は、カテゴリ点検型CoT（Category-Scanning）の導入により、適合率を維持したまま再現率（Recall）を劇的に向上（ベースライン比 $+7.5$ ポイント）させた点にある。
この精度の差は、モデルのアプローチの違い、すなわち\textbf{「ボトムアップな用語抽出」と「トップダウンな仮説検証」の差異}に起因すると考えられる。

従来のSimple手法や用語起点型CoTは、文中からアスペクト語（「食事」「部屋」など）を発見し、それを起点に感情を判定する「抽出（Extraction-First）」のアプローチであった。この手法は、人間が文章を読む際のヒューリスティック（目立つ単語に注目する処理）に近く、効率的である反面、手がかりとなる単語が存在しない暗示的な表現に対しては無力であった。

対して、提案手法であるカテゴリ点検型は、7つのカテゴリすべてに対し「このカテゴリに関する記述はあるか？」と問いかけ続ける「検証（Verification-First）」のアプローチである。
人間にとっては認知負荷が高く冗長なこの全件走査プロセスを、疲労を知らないモデルに強制的に実行させることで、微細な根拠（例：「待たされた」という状況）をも漏らさず拾い上げることを可能にした。
この設計思想の転換こそが、アスペクトカテゴリ感情分析における長年の課題であった抽出漏れ（Missed）の大幅な削減に繋がったと結論付けられる。

\subsubsection{論理的推論による過剰検出の抑制メカニズム}
一般に、抽出漏れを防ごうとしてモデルの感度を高めると、関係のない箇所まで反応してしまう過剰検出（Hallucination）が増加し、適合率が低下するトレードオフが発生する。
実際、用語起点型CoTでは抽出漏れが減少した一方で過剰検出が増加し、適合率の低下を招いた（表\ref{tab:error_comparison}参照）。

しかし、カテゴリ点検型CoTでは、抽出漏れを約$30\%$削減しながらも、過剰検出の増加をベースライン同等レベルに抑制することに成功している。
これは、CoTの推論プロセス（STEP1）において、カテゴリの有無だけでなく「根拠（Evidence）」の明示を求めた効果であると考えられる。
「なんとなく怪しい」で反応するのではなく、「〇〇という記述があるから該当する」という論理的な裏付け（Grounding）をモデルに行わせたことで、根拠のない幻覚的な抽出がフィルタリングされ、結果として高い質の推論が保たれたといえる。

\subsubsection{推論プロセスの自然な獲得}
学習戦略（損失関数の重み $\alpha$）に関する分析では、人為的に中間推論や回答を重視させるよりも、重み付けを行わない（Normal）設定が最も高性能であるという結果が得られた。
これは、T5のような言語モデルにとって、推論（STEP1, 2）と回答（STEP3）は独立したタスクではなく、一連の不可分な思考の流れ（Stream of Thought）として処理されていることを示唆している。
無理に回答部分のみを重視させると、その前段にある推論の生成が疎かになり、結果として論理の破綻を招く。
したがって、構造化されたプロンプトを与えるだけで、モデルは十分に有用な推論パターンを学習可能であり、過度な損失調整は不要であるという知見が得られた。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結論}
\label{chap:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{まとめ}
本研究では、アスペクトカテゴリ感情分析（ACSA）において、従来のモデルが苦手としていた「暗示的な評価表現」の抽出精度向上を目的とし、大規模言語モデルの推論能力を中間推論（Chain of Thought）として導入する手法について検証を行った。
特に、人間がレビューを解釈する際の論理プロセスを模倣するため、以下の2つの推論形式を設計・比較した。
\begin{enumerate}
    \item \textbf{用語起点型}: 文中のアスペクト語を抽出してから分類を行うボトムアップ手法
    \item \textbf{カテゴリ点検型}: 定義された全カテゴリに対し、その有無と根拠を網羅的に検証するトップダウン手法
\end{enumerate}

実験の結果、提案手法であるカテゴリ点検型CoTは、ベースライン手法と比較してF1スコアを大幅に向上させた。
特筆すべきは、再現率（Recall）において $0.075$ ポイントという劇的な改善を達成しつつ、適合率（Precision）の低下を抑制できた点である。
定性分析においても、「待たされた」といったアスペクト語を含まない記述に対し、文脈から論理的に「サービス」カテゴリを導き出す様子が確認された。

以上の結果より、ACSAタスクにおいては、表層的な単語の出現に依存する「抽出」のアプローチよりも、推論過程において全カテゴリを強制的に走査する「検証」のアプローチが極めて有効であり、長年の課題であった抽出漏れ（Missed）の問題を解決する強力な手段となると結論付ける。

\section{今後の展望}
本研究の成果を発展させるため、以下の課題が今後の展望として挙げられる。

第一に、\textbf{カテゴリ定義の境界における曖昧性の解消}である。
エラー分析の結果、「大浴場の廊下（風呂か設備か）」のように、人間でも判断が分かれるような事例において誤分類が発生していた。これを解決するためには、推論ステップにおいて、カテゴリの包含関係や定義をより厳密にモデルへ教示するプロンプト設計が必要と考えられる。

第二に、\textbf{推論コストの削減}である。
提案手法は中間推論を出力するため、通常のラベル生成と比較してトークン数が多くなり、推論時間を要する。実用化に向けては、学習時のみCoTを用い、推論時はラベルのみを出力させるような蒸留手法の検討や、推論プロセスの効率化が求められる。

第三に、\textbf{他ドメインへの汎用性の検証}である。
本実験では宿泊施設のレビューを用いたが、製品レビューや飲食店レビューなど、他のドメインにおいても「カテゴリ点検型」のアプローチが有効であるか検証する必要がある。特に、カテゴリ数が数十個に及ぶような多クラス分類タスクにおいて、点検型のアプローチがどの程度スケーラビリティを持つかは興味深い研究課題である。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{謝辞}
本研究を進めるにあたり、多大なる支援と貴重な助言をいただいた岐阜大学電気電子・情報工学科情報コース准教授松本忠博先生に深く感謝を申し上げます。また、研究に関する助言をいただいた同研究室の方々にも感謝申し上げます。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{junsrt}  
\bibliography{ref}         

\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{付録}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
