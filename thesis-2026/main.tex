\documentclass[dvipdfmx]{thesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 基本設定

%\論文名{2025年度 修士論文}
\論文名{2026年度 卒業論文}
%\所属{岐阜大学大学院 自然科学技術研究科 知能理工学専攻 知能情報学領域
\所属{岐阜大学 工学部 電気電子・情報工学科 情報コース}
\学生番号{1243440498}
\氏名{伊藤 柊太朗}
\指導教員{松本 忠博}
\題目{日本語アスペクトカテゴリ感情分析における推論過程の導入による有効性検証}
%\日付{2026年2月x日}
\日付{2026年2月}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ユーザ定義

% …… ご自由に定義してください ……
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
% 図のディレクトリ
\graphicspath{{./pics/}}
\usepackage{booktabs}    % 高品質な横線（\toprule, \midrule, \bottomrule）を使うため
\usepackage{multirow}    % セルを縦方向に結合するため
\usepackage{array}       % 表の列幅指定や配置を細かく制御するため
\usepackage{amssymb} % \pm 記号用

% 定理，定義
%\usepackage{amsthm}
%\theoremstyle{definition}
\newtheorem{theorem}{定理}
\newtheorem{definition}[theorem]{定義}
%\newtheorem*{definition*}{定義}
\newtheorem{example}{例}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 表紙と目次 (以下はお約束の呪文)
\begin{document}
\maketitle
\frontmatter
\tableofcontents
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{序論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{研究背景}
 近年，インターネットおよび電子商取引（Eコマース）やSNSの普及に伴い，オンライン上のユーザ生成コンテンツ(レビューやSNS投稿など)が爆発的に増加している．これらのレビューや投稿から個々のユーザの意見を分析・理解することは，製品やサービスの改善，およびマーケティング戦略の立案において不可欠である．しかし，膨大なテキストデータを人手で処理することは非効率的であり，多大なコストを要する．そのため，近年は機械学習や深層学習を用いた自然言語処理技術による感情分析が幅広く研究されている．
 
従来の感情分析は，文や文書全体に対してポジティブ，ネガティブ，あるいはニュートラルのいずれか一意の感情極性を判定する手法が主流であった．しかし，実際には一つの文中に複数のトピックが含まれ，それぞれに対して異なる感情が示されることも少なくない．例えば，ホテルやレストランのレビュー文として「料理はおいしいが，店員の態度が悪かった」といったレビュー文がある場合に，この文には，「料理」という側面に対してはポジティブな意見をもち，「店員の態度」に対してはネガティブな意見を持つことが分析できる．上記の例のように，単一の感情極性を割り当てるだけでは，ユーザの多面的な評価を正確に捉えることは困難である．このような課題に対し，文中に含まれる側面（アスペクト）ごとに感情を判定する手法をアスペクトベース感情分析(Aspect Based Sentiment Analysis:  ABSA)という．アスペクトベース感情分析は，従来の感情分析と比較して細粒度な分析が可能であり，ECサイトなどでのレビュー文の分析など多くの場面での実用化が期待され，研究が行われている．
 
しかし，アスペクトベース感情分析はその対象の細かさから，データセットのアノテーションコストが従来の感情分析よりも高いというデメリットがあり，日本語でのデータセット数はかなり少ない．その影響もあり，日本語を対象としたアスペクトベース感情分析の研究はいまだ限定的である．日本語ABSAデータセットとしてよく利用される楽天トラベルレビューデータセットを使用した，日本語でのアスペクトベース感情分析の研究は，数少ない日本語データセットである「楽天トラベルレビューデータセット」を用いた先行研究（西元らによる研究\cite{nishimoto2025}）では，複数のモデルを段階的に用いる分類手法（パイプライン手法）が主眼に置かれてきた．しかし，パイプラインを用いた分類手法には以下の二つの大きな問題点がある．第一に，前段のモデルによる誤りが後続のモデルに波及するエラー伝搬（Error Propagation）の問題である．第二に，文中に直接的な名詞が現れない場合に側面を同定できない暗黙的な側面（暗示的アスペクト）の検出漏れである．これらの問題により，特に日本語特有の文脈依存性の高い表現において，十分な精度を得られないという課題が残されている．

\section{研究の目的}
本研究の目的は，前節で述べた分類モデルを用いたパイプライン手法における課題を解決し，日本語アスペクトカテゴリ感情分類の精度を向上させることである．
具体的には，日本語で事前学習されたT5-baseモデルを用いた生成的手法（Generative Approach）を採用することで，分類モデルを用いた手法よりも表現の幅を広げ、単一のモデル（シングルモデル）による高精度な分析を目指す．さらに，大規模言語モデルの持つ推論能力を学習に取り入れるFine-tune-CoT手法を用いることで，従来手法では困難であった暗示的な意見の抽出精度の向上を図り、日本語アスペクトカテゴリ分析における、中間推論の導入の有効性を検討する。

\section{論文の構成}
本論文の構成は以下の通りである．

\begin{itemize}
    \item \textbf{第2章：事前知識} \\
    本研究の基礎となるアスペクトベース感情分析（ABSA）の定義，および本研究で使用する言語モデルや推論手法に関する事前知識について解説する．
    
    \item \textbf{第3章：関連研究} \\
    日本語ABSAに関する先行研究を概観し，既存の分類手法との違いや本研究の立ち位置について述べる．
    
    \item \textbf{第4章：予備実験：T5モデルによる直接生成手法} \\
    予備実験としてT5モデルを用いた直接生成手法（ベースライン）による検証を行い，直接生成手法における課題，特に暗示的アスペクトの検出漏れについて議論する．
    
    \item \textbf{第5章：提案手法：Fine-tune-CoTを用いた推論過程の導入} \\
    前章で明らかになった課題を解決するための提案手法として，Fine-tune-CoT手法を用いた推論過程の導入について詳述する．ここでは，ボトムアップ型およびトップダウン型の2つの推論パターンについて説明する．
    
    \item \textbf{第6章：評価実験} \\
    提案手法の有効性を検証するための評価実験を行い，ベースライン手法との比較結果および推論精度の分析や定性分析結果について述べる．
    
    \item \textbf{第7章：結論} \\
    本研究で得られた知見をまとめ，結論と今後の課題について述べる．
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{事前知識}
本章では、研究を理解する上で必要となる事前知識について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{アスペクトベース感情分析 (ABSA)}

\subsection{従来の感情分析とその課題}
自然言語処理における感情分析（Sentiment Analysis）は，テキストから著者の主観的な意見や感情を抽出し，その極性（ポジティブ，ネガティブ，ニュートラル）を判定するタスクである．これは製品レビューの分析やSNSのモニタリングなど，マーケティング分野で広く応用されている．

しかし，従来の感情分析は主に文書単位（Document-level）や文単位（Sentence-level）で行われるため，一つの文中に相反する意見が含まれる場合には対応が困難である．
例えば，「料理は美味しいが，店員の態度は悪かった」というレビューに対して，文全体で一つの極性を割り当てようとすると，ユーザの真意（料理への称賛とサービスへの不満）を取りこぼしてしまうことになる．

\subsection{ABSAの定義と4要素}
従来の感情分析（Sentiment Analysis）が，文や文書全体に対して一つの感情極性を判定するのに対し，アスペクトベース感情分析（Aspect-Based Sentiment Analysis: ABSA）は，より細粒度（fine-grained）な意見分析を行うタスクである \cite{survey}．
ABSAでは，主に以下の4つの感情要素（Sentiment Elements）を扱う．

\begin{enumerate}
    \item \textbf{アスペクトカテゴリ ($c$)}:
    事前に定義された属性カテゴリ（例：レストランドメインにおける「料理 (food)」，「サービス (service)」など）．
    
    \item \textbf{アスペクト語 ($a$)}:
    文中に明示的に現れる評価対象の単語（例：「\textbf{ピザ}はおいしい」における「ピザ」）．ターゲットとも呼ばれる．
    
    \item \textbf{意見語 ($o$)}:
    評価対象に対する感情や判断を表す語句（例：「ピザは\textbf{おいしい}」における「おいしい」）．
    
    \item \textbf{感情極性 ($p$)}:
    評価の方向性（ポジティブ，ネガティブ，ニュートラル）．
\end{enumerate}

----ABSA概要の図(ACSAとの対比)-----

Zhangら \cite{survey} は，ABSAの問題を「テキスト中の関心のある感情要素（単一または複数の組み合わせ）を特定する問題」と定義している．

\subsection{タスクの分類：単一タスクと複合タスク}
ABSAの研究分野では，目的に応じて多様なサブタスクが提案されている．これらは，抽出対象となる要素の数や関係性に基づき，「単一タスク（Single ABSA Tasks）」と「複合タスク（Compound ABSA Tasks）」に大別される \cite{survey}．

\begin{itemize}
    \item \textbf{単一タスク}: 
    4つの要素のうち，いずれか一つを抽出・分類するタスクである．
    例えば，文中のアスペクト語 $a$ のみを抽出する「アスペクト語抽出 (Aspect Term Extraction: ATE)」や，特定のアスペクトに対する感情極性 $p$ を判定する「アスペクト感情分類 (Aspect Sentiment Classification: ASC)」などがこれに該当する．
    
    \item \textbf{複合タスク}: 
    複数の要素を同時に，かつ相互の関係性を考慮して抽出するタスクである．
    近年では，単一の要素だけでなく，要素間の依存関係を捉えることが重要視されており，アスペクト語と意見語のペア $(a, o)$ を抽出するタスクや，アスペクト・意見・感情の三つ組 $(a, o, p)$ を抽出する「アスペクト感情三つ組抽出 (Aspect Sentiment Triplet Extraction: ASTE)」などが活発に研究されている．
\end{itemize}

\subsection{アスペクトカテゴリ感情分析 (ACSA)}
本研究で扱う「アスペクトカテゴリ感情分析 (Aspect Category Sentiment Analysis: ACSA)」は，入力文に対して「アスペクトカテゴリ ($c$)」と「感情極性 ($p$)」のペア $(c, p)$ を抽出する複合タスクである．

ACSAの最大の特徴は，文中に評価対象を示す具体的な単語（アスペクト語）が存在しない場合でも分析が可能である点である．
例えば，「値段が高すぎる」という文には，「価格」という単語は含まれていないが，ACSAでは「価格 (Price)」カテゴリに対するネガティブな評価として検出することが求められる \cite{survey}．
このように，ACSAは暗示的な意見（Implicit Opinion）を扱う上で実用性が高く，Eコマース等のレビュー分析において重要な役割を果たす．

----ACSA概要の図(ABSAとの対比を説明？)-----

\section{言語モデルについて}

\subsection{T5}
T5（Text-to-Text Transfer Transformer）\cite{t5} は，2019 年に Google が提案した自然言語処理モデルであり，機械翻訳，文書要約，質問応答，文書分類など多岐にわたるタスクにおいて，当時の最高性能（SOTA）を達成した．T5 は，BERT のようなエンコーダのみのモデルや GPT のようなデコーダのみのモデルとは異なり，Transformer のエンコーダ・デコーダ構成を採用している．その最大の特徴は，あらゆる自然言語処理タスクを「入力テキストを出力テキストに変換する（Text-to-Text）」問題として統一的に扱う点にある．

T5 は，C4（Colossal Clean Crawled Corpus）と呼ばれる大規模なクリーニング済みウェブテキストデータセットを用いて事前学習されている．事前学習タスクとしては，BERT の MLM に似た「スパン破損（Span-corruption）」と呼ばれるタスクが採用されている．これは，入力文中の連続するトークン列（スパン）をランダムにマスクし，デコーダ側でそのマスクされた部分の文字列を生成・復元させるタスクである．これにより，モデルは文脈理解能力とテキスト生成能力を同時に学習することができる．

そして，事前学習した T5 を特定のタスクに適応させるためのファインチューニングにおいても，この Text-to-Text の枠組みが一貫して適用される．BERT のように下流タスクに応じて出力層（分類ヘッドなど）を追加・変更する必要はなく，すべてのタスクで同一のモデル構造と損失関数を使用する．例えば，文書分類タスクであっても，クラスラベルのIDを出力するのではなく，「positive」や「negative」といったラベルのテキストそのものを生成させることで分類を行う．この統一的なアプローチにより，多様なタスクに対して効率的に転移学習を行うことが可能となっている．

本研究では、sonoisa氏が公開しているT5モデルである、Wikipediaの日本語ダンプデータ、OSCAR、CC-100の日本語コーパス（約100GB）を用いて事前学習を行ったT5-base-ver1.1アーキテクチャのモデル\cite{t5}を使用した。

\subsection{gpt-oss-20B}
gpt-oss-20b\cite{gpt-oss}は，2025年8月に OpenAI が公開したオープンウェイトの推論モデルであり ，エージェントワークフロー内での使用を想定し，Web 検索や Python コード実行などのツール利用や高度な推論能力を備えている ．本モデルは，GPT-2 および GPT-3 のアーキテクチャに基づいた自己回帰的な Mixture-of-Experts（MoE）トランスフォーマーであり ，総パラメータ数は約 209 億（20.9B）である．MXFP4 形式への量子化により重みを 4.25ビットで表現することで，メモリ使用量を削減し，16GBのメモリを持つシステムでも動作可能という特徴がある ．

事前学習には，STEM やコーディング，一般知識に焦点を当てた数兆トークンのテキストデータが用いられており ，CBRN（化学・生物・放射性物質・核）などの有害なコンテンツのフィルタリングも行われている ．事前学習後には，OpenAI o3 と同様の思考の連鎖（Chain-of-Thought）を用いた強化学習（RL）によってポストトレーニングが行われ，推論能力やツール利用能力が強化されている ．

また，システムプロンプトで「low」「medium」「high」の推論レベルを指定することで，タスクに応じた推論の深さを調整できる機能を有している ．さらに，安全性に関しては，意図的なジェイルブレイクへの耐性や，「Instruction Hierarchy（指示の階層）」への準拠を学習させることで，システムメッセージの指示をユーザーメッセージよりも優先させる仕組みが導入されている ．

\section{CoT（chain of thought）}
CoT（Chain-of-Thought Prompting）\cite{CoT}は，2022 年に Google の Wei らによって提案されたプロンプトエンジニアリングの手法であり，算術推論や常識推論，記号推論など，多段階の推論を必要とする複雑なタスクにおいて，大規模言語モデル（LLM）の性能を飛躍的に向上させることが示されている．CoT は，従来の入力に対して直接的な回答のみを求める標準的なプロンプティング（Standard Prompting）とは異なり，最終的な回答に至るまでの「中間的な推論ステップ（intermediate reasoning steps）」と呼ばれる一連の思考過程をモデルに生成させるという特徴がある．

CoT は，主に Few-shot プロンプティングの枠組みで用いられ，モデルに与える数ショットの例示（demonstrations）の中に，質問と回答のペアだけでなく，その回答を導き出すための論理的な思考プロセス（思考の連鎖）を自然言語で記述して含める．これにより，モデルは提示された思考パターンを模倣し，未知の入力に対しても問題を段階的に分解して解くことができるようになる．

\section{Fine-tune-CoT}
Fine-tune-CoT\cite{Fine-turn-CoT}は、KAISTの研究者らによって提案された、大規模言語モデル（LLM）の推論能力を小型モデルに継承させるための学習手法である。従来、複雑な問題を段階的に解く「Chain-of-Thought（CoT）推論」は、パラメータ数が100Bを超える巨大なモデルでのみ発現する創発的能力と考えられてきた。Fine-tune-CoTは、巨大なモデルを「教師」として利用し、そこから得られた推論過程を「生徒」である小型モデルに学習させることで、このモデル規模の制約を打破し、小規模パラメータモデルでも高度な推論を可能にすることを目的としている。

この手法のプロセスは、大きく分けて「推論生成」「精査（キュレーション）」「ファインチューニング」の3つのステップで構成される。まず、GPT-3 175Bなどの巨大な教師モデルに対し、「一歩ずつ考えよう（Let's think step by step）」というZero-shot-CoTプロンプトを用いて、特定の問題に対する中間的な推論ステップ（ラショナル）と回答を生成させる。次に、教師モデルが導き出した回答が正解と一致するものだけをフィルタリングし、「問題」を入力、「推論過程＋回答」を出力とする学習用データセットを作成する。これにより、生徒モデルは単に答えを予測するだけでなく、論理的な思考プロセスそのものを模倣するように学習することができる。

さらに、学習効果を最大化するために多様な推論（Diverse Reasoning）という拡張手法が導入されている。これは、一つの問題に対して教師モデルから複数の異なる推論経路を生成させ、学習データを拡充するアプローチであり、生徒モデルの性能を劇的に向上させる要因となっている。この手法をT5やFlan-T5といった小型のエンコーダ・デコーダ型モデルに適用した結果、特定のタスクにおいて0.3B（3億）規模の極めて小さなモデルが、175Bの教師モデルを凌駕する性能を達成した。Fine-tune-CoTは、巨大モデルへの依存を減らし、実社会のアプリケーションにおいて効率的かつ解釈可能な推論モデルを展開するための重要な道筋を示している

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{関連研究}
本章では，既存手法の説明と本研究の新規性について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{日本語データでのアスペクトベース感情分析における従来手法}
日本語のABSA、特に本研究でも使用する「楽天トラベルレビューデータセット」\cite{rakuten}を用いた研究としては、西元ら による取り組み\cite{nishimoto2025}が挙げられる。彼らは、BERTをベースとした複数の小分類器（Entity ClassifierとAttribute Classifier）を用意し、それらを統合（メタモデル化）することでアスペクトカテゴリと感情極性をラベルとして14カテゴリ分類する手法（Mpm+Tの改良版）を提案している 。
このような従来の分類（Classification）ベースの手法は、感情分析を「事前に定義されたクラスへの割り当て問題」として扱う。しかし、このアプローチには、ラベル（カテゴリ名や感情極性）が持つ意味情報（Semantics）をモデルが十分に活用できないという課題がある 。また、パイプライン的に複数のモデルを組み合わせる手法は、エラー伝搬のリスクやモデル構成の複雑化を招く可能性がある。
本研究では、よりシンプルで汎用的な単一モデルによる解決を目指し、「テキスト生成（Generation）」として定式化することで、単一のモデルでシンプルかつ高精度な分析を目指す。

\section{生成型アスペクトベース感情分析の進展}
近年、事前学習済み言語モデルの発展に伴い、ABSAタスクをテキスト生成問題として解く生成型アプローチが注目されている。
Zhangら は、T5モデル を用いた統一的な生成フレームワークである **GAS (Generative Aspect-based Sentiment Analysis)** を提案した\cite{gas} 。GASでは、ABSAのタスクをSequence-to-Sequenceの形式に変換し、入力文に対して目的とする感情要素（アスペクト語や感情極性など）を自然言語のテキストとして直接生成させる。特に彼らが提案した「抽出形式 (Extraction-style)」 は、`(アスペクト, 感情)` のようなペアを直接出力系列として学習させることで、従来の分類手法を上回る性能を示した 。

本研究は、このZhangらの生成型アプローチを基礎としている。しかし、GASはあくまで最終的な「答え」を直接生成するものであり、なぜその結論に至ったかという「思考のプロセス」はブラックボックスのままである。
本研究の独自性は、この生成プロセスに 推論過程 (Chain of Thought)を明示的に導入する点にある。特に、文脈中にアスペクト語が明示されない暗示的な意見（Implicit Opinion）に対して、論理的な推論ステップを挟むことで、生成モデルの解釈能力と予測精度のさらなる向上を図る。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{予備実験：T5モデルによるベースライン検証}
\label{chap:preliminary_experiment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，提案手法の導入に先立ち，日本語データを用いたT5モデルでの直接生成手法（GASフレームワーク）の基本性能を確認するための予備実験について述べる．

\section{実験目的}
Zhangら \cite{gas} は，英語データセットを用いたABSAにおいて，T5モデルを用いた統一的な生成フレームワークであるGAS (Generative Aspect-based Sentiment Analysis) の有効性を示した．
しかし，日本語のACSA（アスペクトカテゴリ感情分析）タスクにおけるGASの適用事例や，その有効性は十分に検証されていない．
そこで本予備実験では，日本語の楽天トラベルレビューデータセットを用い，GASフレームワークを適用した場合のベースライン精度を明らかにする．この結果を、本研究における提案手法の評価基準（ベースライン）とする。
あわせて，レビュー文を入力とする際に，対象文のみを与える場合と，前の文脈情報（Context）を含める場合とで精度にどのような差異が生じるかを検証する．

\section{実験設定}

\subsection{データセットと前処理}
本研究では，楽天グループ株式会社が国立情報学研究所（NII）を通じて提供している「楽天トラベルレビュー：アスペクト・センチメントタグ付きコーパス」\cite{rakuten} を使用した．
本コーパスは，約12,476件のレビューから文単位に分割した約76,000件のレビュー文に対し，以下の7種類のアスペクトカテゴリと，それぞれの感情極性（ポジティブ・ネガティブ）が付与されたマルチラベルデータセットである．

\begin{itemize}
    \item \textbf{アスペクトカテゴリ}: 朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋
    \item \textbf{感情極性}: ポジティブ ($1$)，ネガティブ ($0$)
\end{itemize}

本実験では，全データ（76,624文）から，以下の基準に基づき不適切なデータを除外した．

\begin{itemize}
    \item \textbf{言語および品質に起因する除外}
    \begin{itemize}
        \item 日本語以外の言語で記述されたサンプル、および判読不能なノイズを含むサンプル。
    \end{itemize}
    
    \item \textbf{モデルの制約および計算効率に起因する除外}
    \begin{itemize}
        \item 日本語T5モデルのトークナイザで処理した際、トークン数が500を超えるサンプル。これは、モデルの最大入力長制限である512トークンを考慮したものである。
    \end{itemize}
    
    \item \textbf{タスク設定に起因する除外}
    \begin{itemize}
        \item 定義された7つのアスペクトカテゴリのいずれにも該当しないサンプル。
        \item 同一のアスペクトカテゴリに対し、ポジティブおよびネガティブの相反する感情極性が同時に付与されているサンプル。
    \end{itemize}
    
    \item \textbf{データの重複に起因する除外}
    \begin{itemize}
        \item 内容が完全に重複するレビュー文。過学習の防止および評価の妥当性を維持するため、ユニークなサンプルのみを抽出した。
    \end{itemize}
\end{itemize}

上記の前処理を経た有効データ50,406件から，学習データ20,000件，検証データ2,000件，評価用テストデータ2,000件を抽出した．
なお、楽天トラベルのデータセットには複数のアスペクトカテゴリを含むレビューが多く含まれるため完全な均等化は困難であったが、可能な限り各カテゴリの分布が均一になるようランダムサンプリングにより調整を行った．各データセットの詳細は表\ref{tab:dataset_detail}に示す通りである．

% 各データセットの詳細(データセット & 文数 & 総ラベル数 & 平均ラベル数/文)
\begin{table}[h]
    \centering
    \caption{各データセットの詳細}
    \label{tab:dataset_detail}
    \begin{tabular}{|p{2.0cm}|p{11.0cm}|}
    \hline
    \textbf{none} & none \\ \hline
    \end{tabular}
\end{table}


\subsection{生成タスクへの変換（ラベル形式）}
本研究では分類問題を「テキスト生成問題」として扱うため，Zhangら \cite{gas} の抽出形式（Extraction-style）を参考に，教師データのラベル形式を変換した．
具体的には，出力ターゲットを「\texttt{カテゴリ:感情極性}」の形式とし，複数の意見が含まれる場合は垂直バー「\texttt{|}」で連結する形式を採用した．
変換例を表\ref{tab:label_example}に示す．

\begin{table}[h]
    \centering
    \caption{生成タスクにおける入出力データの例}
    \label{tab:label_example}
    \begin{tabular}{|p{2.0cm}|p{11.0cm}|}
    \hline
    \textbf{入力文} & 立地はいいと思いますが、トイレにはこばえが数匹いて、朝御飯な味噌汁なんかは具なしでした。 \\ \hline
    \textbf{出力ラベル} & 立地:ポジティブ\texttt{|}設備・アメニティ:ネガティブ\texttt{|}朝食:ネガティブ \\ \hline
    \end{tabular}
\end{table}

\subsubsection{出力の正規化処理}
生成モデルは自由なテキストを出力するため，出力されたアスペクトカテゴリ名に微細な誤字や表記ゆれが含まれる可能性がある．
例えば，「サービス」を「サービ」と出力した場合，これを単純な不一致として扱うとモデルの本来の性能を過小評価する恐れがある．

そこで本実験では，先行研究を参考にモデルの出力した各用語に対し，レーベンシュタイン距離（編集距離）を用いた正規化処理を適用した．

レーベンシュタイン距離とは、一方の文字列をもう一方の文字列に変形させるために必要な「挿入」「削除」「置換」の最小操作回数を定義したものである。
\begin{itemize}
    \item \textbf{挿入: 文字を追加する（例：「サービ」 $\rightarrow$ 「サービ\textbf{ス}」）}
    \item \textbf{削除: 文字を取り除く（例：「サービス\textbf{ッ}」 $\rightarrow$ 「サービス」）}
    \item \textbf{置換: 文字を書き換える（例：「サービ\textbf{ズ}」 $\rightarrow$ 「サービ\textbf{ス}」）}
\end{itemize}


具体的には，出力された単語が事前に定義されたアスペクトカテゴリ集合 $V$（朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋）に含まれない場合，以下の手順で補正を行う．

\begin{enumerate}
    \item 出力語と語彙集合 $V$ 内の各単語との編集距離 $d$ を計算する．
    \item 最も距離が小さい単語を候補とし，その最小距離が $2$ 以下，かつ出力語の長さの半分以下である場合に限り，当該語彙への置き換えを行う．
    \item 上記の条件を満たさない場合は，抽出失敗（None）として扱う．
\end{enumerate}

この後処理により，生成モデル特有の軽微な文字生成ミスを許容し，本質的な感情分析性能を評価する．

\subsection{モデルおよび学習設定}
本実験におけるモデルの選定および学習時のハイパーパラメータの設定について述べる。

\subsubsection{使用モデル}
本研究では、sonoisa氏が公開しているT5モデルである、\texttt{sonoisa/t5-base-japanese-v1.1}を使用した。このモデルは、T5-baseモデルをWikipediaの日本語ダンプデータ、OSCAR、CC-100の日本語コーパスなど約100GBの日本語テキストデータを用いて日本語事前学習を行ったモデルである。

\subsubsection{ハイパーパラメータと学習条件}
モデルの学習における主要な設定値を表\ref{tab:simple_hyperparameters}に示す。

\begin{table}[htbp]
  \centering
  \caption{学習時におけるハイパーパラメータの設定}
  \label{tab:simple_hyperparameters}
  \begin{tabular}{lc} \hline
    項目 & 設定値 \\ \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 64 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\ \hline
  \end{tabular}
\end{table}

最大入力トークン数および出力トークン数は、計算リソースと対象とするデータセットの平均長を考慮し、それぞれ 128 および 64 に設定した。最適化アルゴリズムには AdamW を採用し、学習率を $1.0 \times 10^{-4}$ として固定した。

学習の効率化および過学習の抑制のため、検証データにおける F1 スコアを監視対象としたアーリーストッピング（Early Stopping）を導入した。具体的には、5 エポック連続で F1 スコアの向上が認められない場合に学習を打ち切るよう設定した。また、各エポック終了時に検証データで最も高い精度を示した時点のモデル重みを、最終的な推論に用いる最良のモデルとして保存した。

\subsubsection{実験の頑健性の確保}
実験結果の統計的な妥当性を確保するため、シード値として 42、100、1000 の 3 通りを設定し、それぞれの条件で独立した学習および評価を行った。本論文で報告する精度評価値は、これら 3 回の試行によって得られた結果の平均値である。

\subsection{比較手法} 
本研究では、T5モデルへの入力形式がアスペクトカテゴリ感情分類（ACSA）の精度に与える影響を調査するため、以下の2種類の手法を比較・検証する。第一に、評価対象となるレビュー文のみを入力とする手法（以下、Simple手法）、第二に、対象文にその直前の文脈情報を付加して入力する手法（以下、Simple-context手法）である。

本研究における文脈情報とは、楽天トラベルデータセットにおいて、一つのレビューが文単位で分割・管理されている点を利用し、評価対象文の直前（一つ前のID）に位置する文と定義した。評価対象文がレビューの冒頭である場合など、直前の文が存在しない場合には、文脈情報を「なし」と定義している。文脈情報として複数の文を遡って付与する構成も検討したが、本研究ではT5モデルの最大入力トークン数制限を考慮し、直近の1文のみを採用した。

宿泊レビュー等のユーザー生成コンテンツにおいて、評価対象文は必ずしも一文で意味が完結しているとは限らない。特に、代名詞の指示対象（照応）や、前の文脈に依存した評価対象の省略を正確に把握する必要がある。そこでSimple-context手法では、対象文を\texttt{<}本文\texttt{>}、その直前の文を\texttt{<}文脈文\texttt{>}という特殊タグを用いて構造化し、モデルに明示的に入力する形式を採用した。これにより、モデルが分析対象の範囲を厳密に認識しつつ、周囲の文脈から欠落した情報を補完することで、高精度な判定が可能になると考えられる。

%表\ref{tab:Simple-context_example}に、Simple-context手法における具体的な入出力データの例を示す。本例において、本文の「アメゴの刺身」という記述のみでは、それが朝食と夕食のいずれに対する言及であるかを特定することは困難である。しかし、文脈文に含まれる「夕食」という情報をモデルが参照することで、適切なカテゴリ（夕食）を導出することが可能となる。Simple-context手法は、このような文脈依存性の高いケースにおける分類精度の向上を主眼としている。

\begin{table}[h]
\centering
\caption{Simple-context手法における入出力データの例}
\label{tab:Simple-context_example}
\begin{tabular}{|p{2.5cm}|p{10.5cm}|}
\hline
\textbf{項目} & \textbf{内容} \\ \hline 
\textbf{入力テキスト} & \texttt{<}文脈文\texttt{>}プラン通り、囲炉裏を前にした夕食は予想以上に最高。\texttt{<}/文脈文\texttt{>} 
\texttt{<}本文\texttt{>}特に、アメゴの刺身はとても美味しかったです！\texttt{<}/本文\texttt{>} \\ \hline 
\textbf{出力ラベル} & 夕食:ポジティブ \\ \hline 
\end{tabular}
\end{table}

\subsection{評価指標}
評価方法として、本実験では、正解率(accuracy)、適合率(Precision)、再現率(Recall)、F1値(F1-score)の評価指標を用いて、アスペクトカテゴリ分析結果を評価した。それぞれの評価指標について説明する。
\subsection{評価指標}
本研究におけるアスペクトカテゴリ感情分類（ACSA）の結果を定量的に評価するため、以下の3つの指標を用いる。本タスクは一つの文に対して複数のアスペクトカテゴリおよび感情値のペア（例：部屋：ポジティブ、サービス：ネガティブ）を抽出するマルチラベル分類であるため、正解ラベルの集合とモデルの出力集合を比較することで各指標を算出する。なお、算出にあたっては、以下の3つの要素を定義する。

\begin{itemize}\item \textbf{真陽性 (True Positive: TP)}：モデルが予測したカテゴリと感情のペアが、正解ラベルに存在する場合。\item \textbf{偽陽性 (False Positive: FP)}：モデルが予測したペアが、正解ラベルに存在しない場合（余計な出力）。\item \textbf{偽陰性 (False Negative: FN)}：正解ラベルに含まれるペアを、モデルが予測できなかった場合（見落とし）。
\end{itemize}

\subsubsection{正解率 (Accuracy)}正解率は、全テストデータのうち、モデルの出力したカテゴリおよび感情のペアが、正解ラベルと完全に一致したデータの割合を示す。本研究のようなマルチラベルタスクにおいては、全てのラベルが一致した場合のみを正解とする。全体の分類性能を直感的に把握するために用いるが、一部のカテゴリのみを正解した場合が評価されないため、後述の適合率や再現率と併せて考察する必要がある。

\subsubsection{適合率 (Precision)}適合率は、モデルが「正解」と予測した全ペアのうち、実際に正解ラベルに含まれていたペアの割合を示す。以下の式で定義される。
\[\text{Precision} = \frac{\text {TP}}{\text {TP} + \text {FP}}\]
本指標が高いことは、モデルが「根拠のない誤った評価」や「存在しないカテゴリ」を不必要に出力（ハルシネーション）していないことを意味し、出力結果の信頼性を表す。
\subsubsection{再現率 (Recall)}再現率は、正解ラベルに含まれる全ペアのうち、モデルが正しく予測できたペアの割合を示す。以下の式で定義される。
\[\text{Recall} = \frac{\text {TP}}{\text {TP} + \text {FN}}\]
本指標が高いことは、レビュー文に含まれる多様な評価項目を漏らさず抽出できていることを意味する。

\subsubsection{F1値 (F1-score)}F1値は、適合率と再現率の調和平均であり、以下の式で定義される。
\[F1 = \frac{2 \cdot \text {Precision} \cdot \text {Recall}}{\text {Precision} + \text {Recall}}\]
適合率と再現率はトレードオフの関係にあることが多いため、これらを統合したF1値を用いることで、モデルの総合的な抽出・分類性能を評価する。本研究における各手法の優劣を判断する主要な指標として採用する。

\section{実験結果}
実験結果を表\ref{tab:baseline_overall}および表\ref{tab:baseline_category_f1}に示す．
表\ref{tab:baseline_overall}は先の章で述べた4つの評価指標での比較を示している．また，表\ref{tab:baseline_category_f1}はアスペクトカテゴリごとに分けた際のF1値の比較を示す．
\begin{table}[!ht]
  \centering
  \caption{ベースラインモデルの性能比較（3回の試行による平均 $\pm$ 標準偏差）}
  \label{tab:baseline_overall}
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    Simple    & $0.894 \pm 0.003$ & $0.745 \pm 0.014$ & $0.813 \pm 0.008$ & $0.624 \pm 0.010$ \\
    Simple-context  & $\textbf{0.903} \pm \textbf{0.004}$ & $\textbf{0.760} \pm \textbf{0.005}$ & $\textbf{0.825} \pm \textbf{0.003}$ & $\textbf{0.643} \pm \textbf{0.004}$ \\ \bottomrule
  \end{tabular}
\end{table}

\begin{table}[!ht]
  \centering
  \caption{アスペクトカテゴリごとのF1値の比較}
  \label{tab:baseline_category_f1}
  \begin{tabular}{lcc} \toprule
    アスペクトカテゴリ & Simple (Review-only) & Simple (Context-aware) \\ \midrule
    風呂               & $0.854$ & $\textbf{0.864}$ \\
    夕食               & $\textbf{0.854}$ & $0.845$ \\
    立地               & $0.842$ & $\textbf{0.850}$ \\
    部屋               & $0.818$ & $\textbf{0.830}$ \\
    朝食               & $0.817$ & $\textbf{0.825}$ \\
    設備・アメニティ   & $0.777$ & $\textbf{0.802}$ \\
    \textbf{サービス}  & $0.721$ & $\textbf{0.761}$ \\ \bottomrule
  \end{tabular}
\end{table}

\section{考察と課題}
\subsection{考察：文脈情報の有効性}
実験結果より、文脈情報を付与した Simple (Context-aware) 手法は、レビュー文のみを用いる Simple (Review-only) 手法と比較して、4つの評価指標すべてにおいて上回る結果となった。
特に、総合的な性能を示すF1値では $0.012$ ポイントの向上が確認された。
また、アスペクトカテゴリごとの比較においても、夕食カテゴリを除くほぼすべての項目で精度が向上している。

この結果は、楽天トラベルのようなレビューデータにおいて、代名詞の指示対象（照応）や、文脈に依存して省略された評価対象を正確に捉える上で、前後の文脈情報が一定の有効性を持つことを示唆している。
しかし、その向上幅は限定的であり、単純な文脈の連結だけでは解決できない課題が残されていることも明らかとなった。

\subsection{課題分析}
本実験の結果から明らかになったアスペクトカテゴリ感情分析（ACSA）における課題は、主に以下の2点に集約される。

第一に、\textbf{再現率（Recall）の低さ}である。
両手法ともに、適合率（Precision）が $0.90$ 前後と高い水準にあるのに対し、再現率は $0.75$ 前後と約 $0.15$ ポイントもの乖離が見られた。
これは、モデルが抽出したペアの正答率は高いものの、本来抽出すべきアスペクトと感情極性のペアを数多く見逃している（抽出漏れが多い）ことを意味する。

第二に、\textbf{暗示的なアスペクト表現への対応}である。
カテゴリ別のF1値において、「サービス」カテゴリのスコアが他と比較して顕著に低い結果となった。
エラー分析の結果、「サービス」に関する評価は、「朝食」や「部屋」のように具体的な単語が明示されることが少なく、「待たされた」「気が利かない」といった文脈から読み取る必要がある**暗示的（Implicit）な表現**が大半を占めることが分かった。
従来の単純な生成モデルでは、このような表層的な単語マッチングに依存しない表現を十分に捉えきれていないと考えられる。

\subsection{次章への展望}
上記の問題を解決するためには、人間が無意識に行っている「待たされた $\rightarrow$ 対応が遅い $\rightarrow$ サービス:ネガティブ」といった論理的な推論ステップをモデルに学習させる必要がある。

そこで次章では、T5モデルにACSAの中間推論プロセス（Chain of Thought）を出力させる提案手法について述べる。
推論過程を明示的に扱わせることで、文中に含まれる暗示的なアスペクトカテゴリの抽出能力を向上させ、抽出漏れ（Recallの低さ）の改善を目指す。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{提案手法：Fine-tune-CoTによる推論過程の導入}
\label{chap:proposed_method}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，前章で明らかになった課題（再現率の低さおよび暗示的アスペクトの抽出漏れ）を解決するための提案手法について述べる．

\section{手法の概要 (Fine-tune-CoT)}
\label{sec:finetunecot_overview}

\subsection{Fine-tune-CoTのアプローチ}
本研究では，ACSAタスクにおいて中間推論プロセス（Chain of Thought: CoT）をモデルに学習させるため，Hoら \cite{Fine-turn-CoT} が提案した \textbf{Fine-tune-CoT} の枠組みを採用する．
Fine-tune-CoTは，大規模言語モデル（LLM）が持つ高度な推論能力を，蒸留（Distillation）のアプローチによって小規模モデルに継承させる手法である．

本手法のプロセスは，以下の3つのステップで構成される（図参照）．

\begin{enumerate}
    \item \textbf{推論生成 (Reasoning Generation)}:
    高度な推論能力を持つ教師モデル（本研究では [具体的なモデル名] を使用）に対し，入力文と特定のプロンプトを与え，中間的な推論ステップを含む回答を生成させる．
    
    \item \textbf{精査 (Curation)}:
    教師モデルが生成したデータのうち，最終的な回答が正解ラベルと完全に一致するもののみをフィルタリングする．これにより，誤った推論を含むノイズデータを除外し，高品質な「入力 $\rightarrow$ 推論過程 $\rightarrow$ 回答」のペアを作成する（以下，CoTデータセット）．
    
    \item \textbf{ファインチューニング (Fine-tuning)}:
    作成したCoTデータセットを用いて，生徒モデル（T5）を学習させる．これにより，生徒モデルは単に答えを予測するだけでなく，教師モデルの論理的な思考プロセスそのものを模倣するように学習する．
\end{enumerate}

\subsection{構造化された推論形式の採用}
一般的なCoT（Zero-shot-CoTなど）では「Step-by-stepで考えて」といった指示により多様な自然言語による推論を生成させる．
しかし，本研究で用いるT5のような小規模モデルにとって，自由度の高すぎる推論テキストは学習のノイズとなり，収束を妨げる可能性がある．
T5モデルはSequence-to-Sequence形式の構造変換を得意とする特性があるため，本研究では自由記述ではなく，\textbf{厳密に定義・構造化された推論形式}を採用する．
具体的には，次節で述べる2つの推論パターンを教師モデルに強制してデータを生成し，その有効性を検証する．


----Fine-turn-CoTの図-----


\section{中間推論の形式設計}
\label{sec:reasoning_formats}

本研究では，アスペクトカテゴリ感情分析に適した推論プロセスとして，設計思想の異なる以下の2つの形式を考案した．

\subsection{パターン1：用語起点型 (Term-Oriented Inference)}
用語起点型は，従来のABSAタスクの処理フロー（用語抽出 $\rightarrow$ 分類）をCoTとして言語化した形式である．
文中に明示されている評価対象語（アスペクト語）を起点として推論を展開するため，アスペクト語が明確なケースにおいて高い適合率が期待できる．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 用語抽出] 文中から評価対象となっている語句をすべて抽出する．
        \item[STEP2 カテゴリ分類] 抽出した各用語が，7つの定義済みカテゴリのどれに該当するかを分類する．
        \item[STEP3 感情分析] カテゴリごとに，対応する用語周辺の表現から極性を判定する．
        \item[STEP4 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応。\\
\textbf{CoT出力}:\\
\texttt{<STEP1> レストランスタッフ | 対応}\\
\texttt{<STEP2> レストランスタッフ $\rightarrow$ サービス | 対応 $\rightarrow$ サービス}\\
\texttt{<STEP3> サービス $\rightarrow$ 一番よかった $\rightarrow$ ポジティブ}\\
\texttt{<STEP4> サービス:ポジティブ}
\end{minipage}}

\subsection{パターン2：カテゴリ点検型 (Category-Scanning Inference)}
カテゴリ点検型は，第4章で課題となった「抽出漏れ（Recallの低さ）」と「暗示的アスペクト」に対応するための形式である．
文中の単語に依存せず，事前に定義された7つのカテゴリすべてについて「言及があるか？」を順次確認（スキャン）する検品ロジックを採用している．これにより，具体的なアスペクト語が存在しない場合でも，文脈からの推論を促すことを狙いとしている．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 全カテゴリ点検] 7つのカテゴリすべてに対し，有無とその根拠（該当箇所または文脈）を列挙する．
        \item[STEP2 感情分析] 「あり」と判定されたカテゴリについてのみ，感情極性を判定する．
        \item[STEP3 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応。\\
\textbf{CoT出力}:\\
\texttt{<STEP1>}\\
\texttt{- サービス: あり (根拠: レストランスタッフさんの対応)}\\
\texttt{- 夕食: なし}\\
\texttt{- 朝食: なし}\\
\texttt{- 立地: なし}\\
\dots （中略） \dots\\
\texttt{<STEP2>}\\
\texttt{- サービス: レストランスタッフさんの対応 $\rightarrow$ ポジティブ}\\
\texttt{<STEP3> サービス:ポジティブ}
\end{minipage}}

\section{CoTデータの生成方法}
\label{sec:cot_generation}

本研究では，教師モデルの知識蒸留により，学習用データセット（楽天トラベルレビューデータセットの学習分割）に対して中間推論付きの拡張データセットを作成した．
具体的な手順は以下の通りである．

\subsection{プロンプトによる推論生成}
まず，教師モデル（gpt-oss-20B\cite{gpt-oss}）に対し，元のレビュー文 $x$ と共に，中間推論の生成を促すプロンプト $P$ を入力した．
プロンプトには，タスクの定義，出力フォーマットの指定，および数件のFew-shot事例（入力と理想的なCoT出力のペア）を含めた．
これにより，教師モデルは入力文 $x$ に対し，推論過程 $r$ と最終回答 $y$ を含む系列 $\hat{z} = (r, y)$ を生成する．

\subsection{データの精査（キュレーション）}
教師モデルは常に正しい推論を行うとは限らない．誤った推論や回答を含むデータを生徒モデルに学習させることは，性能低下（ハルシネーションの増大）につながるリスクがある．
そこで，生成されたデータに対して以下のフィルタリング処理を行った．

\begin{enumerate}
    \item \textbf{回答の一致確認}: 
    教師モデルが生成した最終回答 $y$ が，元のデータセットの正解ラベル $y_{gold}$ と完全に一致するかを確認する．
    \item \textbf{形式の整合性確認}: 
    生成された推論過程 $r$ が，指定したフォーマット（\texttt{<}STEP\texttt{>}タグや順序）を遵守しているかを確認する．
\end{enumerate}

上記の条件を満たしたデータのみを学習用データとして採用し，条件を満たさないデータは破棄，または再度生成を行った．
最終的に構築されたCoTデータセット $D_{CoT}$ は，入力文 $x$ と，精査済みの推論付きラベル $z = (r, y_{gold})$ のペアで構成される．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{評価実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{実験目的}
本実験では、日本語の楽天トラベルレビューデータセットを用い、3つの手法の精度を比較する。3つの手法とは、第4章で行った予備実験において最も高精度だったsimple-context手法、提案手法である中間推論を学習させる用語起点型、カテゴリ点検型である。simple-context手法をベースラインとして、CoTデータとしてモデルに推論過程を明示的に扱わせることで、文中に含まれる暗示的なアスペクトカテゴリの抽出能力を向上させ、精度の比較を行う。

\section{実験設定}
CoTデータのハイパーパラメータを表\ref{tab:CoT_hyperparameters}に示す。そのほかデータセット、評価指標、学習条件の設定などは第4章と同様である。
学習戦略としてのモデルに対して「中間推論」と「最終的な回答」のどちらを優先すべきかのトレードオフを探索においてαを0.2, 0.5, 0.8の3値で比較を行う。

\begin{table}[htbp]
  \centering
  \caption{CoTデータにおける学習時のハイパーパラメータ}
  \label{tab:CoT_hyperparameters}
  \begin{tabular}{lc} \hline
    項目 & 設定値 \\ \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 400 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\ \hline
  \end{tabular}
\end{table}
\section{実験結果}
本実験における全体性能の比較を表\ref{tab:proposal_overall}に，アスペクトカテゴリごとのF1スコアの比較を表\ref{tab:proposal_category_f1}に示す．

% --- 全体性能比較の表 ---
\begin{table}[!ht]
  \centering
  \caption{提案手法とベースラインの性能比較（3回の試行による平均 $\pm$ 標準偏差）}
  \label{tab:proposal_overall}
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    Simple (Context-aware)       & $\textbf{0.903} \pm 0.004$ & $0.760 \pm 0.005$ & $0.825 \pm 0.003$ & $0.643 \pm 0.004$ \\
    Term-Oriented (Pattern 1)    & $0.852 \pm 0.004$ & $0.810 \pm 0.005$ & $0.830 \pm 0.004$ & $0.652 \pm 0.005$ \\
    \textbf{Category-Scanning (Pattern 2)} & $0.893 \pm 0.004$ & $\textbf{0.835} \pm \textbf{0.006}$ & $\textbf{0.863} \pm \textbf{0.002}$ & $\textbf{0.700} \pm \textbf{0.001}$ \\ \bottomrule
  \end{tabular}
\end{table}

% --- カテゴリ別F1値の表 ---
\begin{table}[!ht]
  \centering
  \caption{手法別アスペクトカテゴリごとのF1値比較}
  \label{tab:proposal_category_f1}
  \begin{tabular}{lccc} \toprule
    カテゴリ & Simple (Context) & Term-Oriented & \textbf{Category-Scanning} \\ \midrule
    夕食              & $0.845$ & $0.880$ & $\textbf{0.902}$ \\
    風呂              & $0.864$ & $0.878$ & $\textbf{0.897}$ \\
    立地              & $0.850$ & $0.853$ & $\textbf{0.886}$ \\
    朝食              & $0.825$ & $0.853$ & $\textbf{0.871}$ \\
    部屋              & $0.830$ & $0.818$ & $\textbf{0.851}$ \\
    \textbf{サービス} & $0.761$ & $0.743$ & $\textbf{0.836}$ \\
    設備・アメニティ  & $\textbf{0.802}$ & $0.781$ & $0.794$ \\ \bottomrule
  \end{tabular}
\end{table}
\section{分析と考察}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{まとめ}

\section{今後の課題}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{謝辞}

お父さんお母さんありがとう

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{junsrt}  
\bibliography{ref}         

\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{付録}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
