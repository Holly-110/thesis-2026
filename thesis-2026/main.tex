\documentclass[dvipdfmx]{thesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 基本設定

%\論文名{2025年度 修士論文}
\論文名{2025年度 卒業論文}
%\所属{岐阜大学大学院 自然科学技術研究科 知能理工学専攻 知能情報学領域
\所属{岐阜大学 工学部 電気電子・情報工学科 情報コース}
\学生番号{1243440498}
\氏名{伊藤 柊太朗}
\指導教員{松本 忠博}
\題目{\fontsize{23.5}{30}\selectfont
日本語アスペクトカテゴリ感情分析における\\
推論過程の導入による有効性検証}
%\日付{2026年2月x日}
\日付{2026年2月}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ユーザ定義

% …… ご自由に定義してください ……
\usepackage{amsmath}
\usepackage[dvipdfmx]{graphicx}
% 図のディレクトリ
\graphicspath{{./pics/}}
\usepackage{booktabs}    % 高品質な横線（\toprule, \midrule, \bottomrule）を使うため
\usepackage{multirow}    % セルを縦方向に結合するため
\usepackage{array}       % 表の列幅指定や配置を細かく制御するため
\usepackage{amssymb} % \pm 記号用
\usepackage{graphicx}
\usepackage[table]{xcolor} % 表の網掛け用
\usepackage{tcolorbox}

% 定理，定義
%\usepackage{amsthm}
%\theoremstyle{definition}
\newtheorem{theorem}{定理}
\newtheorem{definition}[theorem]{定義}
%\newtheorem*{definition*}{定義}
\newtheorem{example}{例}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 表紙と目次 （以下はお約束の呪文）
\begin{document}
\maketitle
\frontmatter
\tableofcontents
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{序論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{研究背景}
 近年，インターネットおよび電子商取引やSNSの普及に伴い，オンライン上のユーザ生成コンテンツ（レビューやSNS投稿など）が爆発的に増加している．これらのレビューや投稿から個々のユーザの意見を分析・理解することは，製品やサービスの改善，およびマーケティング戦略の立案において不可欠である．しかし，膨大なテキストデータを人手で処理することは非効率的であり，多大なコストを要する．そのため，近年は機械学習や深層学習を用いた自然言語処理技術による感情分析が幅広く研究されている．
 
従来のユーザ生成コンテンツに対する感情分析は，文や文書全体に対してポジティブ，ネガティブ，あるいはニュートラルのいずれか一意の感情極性を判定する手法が主流である．しかし，実際には一つの文中に複数のトピックが含まれ，それぞれのトピックに対して異なる感情が示されることも少なくない．例えば，「料理はおいしいが，店員の態度が悪かった」といったレストランのレビュー文がある場合に，このレビュー文は，「料理」に対してはポジティブな評価であるが，「店員の態度」に対してはネガティブな評価である．上記の例のように，一文に対して単一の感情極性を割り当てるだけでは，ユーザの多面的な意見を正確に捉えることは困難である．このような課題に対し，文中に含まれるアスペクト（トピック）ごとに感情を判定する手法をアスペクトベース感情分析（Aspect-Based Sentiment Analysis; 以下, ABSA）という．ABSAは，従来の感情分析と比較して細粒度な分析が可能であり，ECサイトのレビュー文分析など多くの場面での実用化が期待され，研究が行われている．
 
しかし，ABSAはその対象の細かさから，データセットのアノテーションコストが従来の感情分析よりも高いというデメリットがあり，日本語でのデータセット数はかなり少ない．その影響もあり，日本語を対象としたABSAの研究はいまだ限定的であるという課題が残されている．

\section{関連研究}
\subsection{分類ベースのアプローチ}
日本語のABSA，特に本研究でも使用する\texttt{楽天トラベルレビュー:アスペクト・センチメントタグ付きコーパス}\cite{rakuten}（以下，楽天トラベルデータセット）を用いた代表的な研究として，西元らによる取り組み\cite{nishimoto2025}が挙げられる． 彼らは，BERTをベースとした7つの小分類器を用意し，それらをTransformerエンコーダを用いて統合することでアスペクトカテゴリと感情極性を14クラスに分類する手法を提案している．

このような従来のパイプラインベースの分類手法は，アスペクトカテゴリと感情極性ごとに多数の学習済みモデル（BERT）を用意する必要があるため，モデル構成の複雑化し，モデル全体のパラメータ数が膨大になり，学習や推論における計算コストが著しく増大する．また，複数のモデルを組み合わせるパイプライン手法は，エラー伝搬のリスクを含むという課題も残されている．

\subsection{生成ベースのアプローチ}
近年，事前学習済み言語モデルの発展に伴い，ABSAタスクをテキスト生成問題として解く生成型アプローチが注目されている．
Zhangら\cite{gas}は，T5モデルを用いた統一的な生成フレームワークである GAS（Generative Aspect-based Sentiment Analysis）を提案した．
GASでは，ABSAタスクをSequence-to-Sequence形式に変換し，入力文に対して目的とする感情要素（アスペクトカテゴリや感情極性など）を自然言語のテキストとして直接生成させる．
彼らが提案したExtraction-style（抽出形式）は，（アスペクト, 感情）のようなペアを直接出力系列として学習させることで，従来の分類手法を上回る性能を示した．

しかし，GASなどの既存手法はあくまで最終的な回答を直接生成するものであり，なぜその結論に至ったかという思考のプロセスはブラックボックスのままであるという課題が残されている．本研究では，この生成型アプローチを基盤とし，その課題解決を試みる．

\section{研究の目的}
本研究の目的は，\texttt{楽天トラベルデータセット}\cite{rakuten}を使用し，ABSAのサブタスクの一つである，アスペクトカテゴリ感情分類（Aspect Category Sentiment Analysis; 以下, ACSA）の精度を向上させることである．
具体的には，従来の文全体を入力とし，ラベルを予測する分類手法ではなく，日本語事前学習済みT5モデルを用いた生成アプローチを採用することで入力文に対し，感情要素を含むターゲットシーケンスを生成することを可能にする．これにより表現の幅を広げ，単一の学習モデルによる高精度な分析を目指す．さらに，大規模言語モデルの持つ推論能力を学習に取り入れるFine-tune-CoT手法を用いることで，中間推論過程を明示的にし，なぜその結論に至ったかという思考のプロセスは明確にすることで，生成モデルの解釈能力と予測精度のさらなる向上を検証する．

\section{論文の構成}
本論文の第2章以降の構成を以下に示す． 

\begin{itemize}
    \item \textbf{第2章：事前知識} \\
    本研究の基礎となるアスペクトベース感情分析（ABSA）の定義，および本研究で使用する言語モデルや推論手法に関する事前知識について説明する．
    
    \item \textbf{第3章：T5モデルによる直接生成手法} \\
    予備実験としてT5モデルを用いた直接生成手法（ベースライン）による検証を行い，ベースラインにおける課題について議論する．
    
    \item \textbf{第4章：Fine-tune-CoTを用いた推論過程の導入} \\
    前章で明らかになった課題を解決するための提案手法として，Fine-tune-CoT手法を用いた中間推論過程の導入について説明する．
    
    \item \textbf{第5章：評価実験} \\
    提案手法の有効性を検証するための評価実験を行い，ベースライン手法との推論精度の定量分析結果や定性分析結果について述べる．
    
    \item \textbf{6章：結論} \\
    本研究で得られた知見をまとめ，結論と今後の課題について述べる．
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{事前知識}
本章では，研究を理解する上で必要となる事前知識について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{アスペクトベース感情分析 （ABSA）}

\subsection{ABSAの定義と4要素}
1章でも述べた通り，従来の感情分析が，文や文書全体に対して一つの感情極性を判定するのに対し，アスペクトベース感情分析は，より細かな分析を行うタスクである ABSAでは，主に以下の4つの感情要素を扱う．Zhangら\cite{survey}は，ABSAのタスクを「テキスト中に含まれる，着目すべき感情要素（単一または複数の組み合わせ）を特定する問題」と定義している．

\begin{enumerate}
    \item \textbf{アスペクト用語 （$a$）}:
    文中に明示的に現れる評価対象の単語
    
    （例：「\textbf{ピザ}はおいしい」における「ピザ」）．

    \item \textbf{アスペクトカテゴリ （$c$）}:
    ドメインごとに事前に定義されたカテゴリ
    
    （例：レストランドメインにおける「食べ物」，「サービス」など）．
    
    \item \textbf{意見用語 （$o$）}:
    評価対象に対する感情や判断を表す語句
    
    （例：「ピザは\textbf{おいしい}」における「おいしい」）．
    
    \item \textbf{感情極性 （$p$）}:
    感情の方向性
    
    （例：ポジティブ，ネガティブ，ニュートラル）．
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\columnwidth]{pics/ABSA_cropped.pdf} % フォルダ名/ファイル名
  \caption{ABSAの4つの感情要素例（Zhangら\cite{survey}を基に著者が翻訳・作成）}
  \label{fig:result_comparison}
\end{figure}

\subsection{ABSAタスクの分類}
アスペクトベース感情分析（ABSA）のタスクは，抽出対象の構成要素の複雑さに応じて，単一タスクと複合タスクの2つに大別され，抽出対象の4要素の組み合わせによって表\ref{tab:absa_tasks}のように分類される．
なお，本節では各要素を以下のように表記する．


アスペクト用語: $a$,アスペクトカテゴリー: $c$, 意見用語: $o$, 感情極性: $p$

\begin{table}[htbp]
    \centering
    \caption{ABSAタスクの分類と抽出対象}
    \label{tab:absa_tasks}
    \renewcommand{\arraystretch}{1.3} % 行間を広げて読みやすく
    \small
    \begin{tabular}{c c c p{6.5cm}}
        \hline
        \textbf{分類} & \textbf{タスク名} & \textbf{抽出対象} & \multicolumn{1}{c}{\textbf{概要}} \\
        \hline
        \hline
        \multirow{3}{*}{単一} 
         & ATE & $（a）$ & 文中のアスペクト項を抽出 \\
         & ACD & $（c）$ & アスペクトカテゴリを特定 \\
         & ASC & $（p）$ & 特定対象に対する感情極性を予測 \\
        \hline
        \rowcolor[gray]{0.9}
        \multirow{5}{*}{複合} 
         & \textbf{ACSA} & $\mathbf{（c, p）}$ & \textbf{カテゴリと感情のペアを抽出（本研究の対象）}\\
         & E2E-ABSA & $（a, p）$ & アスペクト項と感情極性のペアを抽出 \\
         & AOPE & $（a, o）$ & アスペクト項と意見項を抽出 \\
         & ASTE & $（a, o, p）$ & アスペクトカテゴリを除く3要素を抽出 \\
         & ASQP & $（c, a, o, p）$ & 4要素すべてを扱う最も完全なタスク \\
        \hline
    \end{tabular}
\end{table}

\subsection{アスペクトカテゴリ感情分析（ACSA）}
本研究で扱うアスペクトカテゴリ感情分析（ACSA）は，入力文に対して「アスペクトカテゴリ（$c$）」と「感情極性（$p$）」のペア$（c, p）$を抽出する複合タスクである．

ACSAの最大の特徴は，文中に評価対象を示す具体的な単語（アスペクト語）が存在しない場合でも分析が可能である点である．ユーザ生成のレビュー文においては主語が欠落または，含まれていない文も多く存在する．たとえば，「このレストランは高すぎる」というレビュー文には，「価格」という単語は含まれていないが，ACSAでは「価格」カテゴリに対するネガティブな評価として検出することが求められる \cite{survey}．
このように，ACSAは文中に含まれる暗示的な意見を扱う上で実用性が高く，レビュー分析において重要な役割を果たす．

\section{使用する言語モデル}

\subsection{T5}
T5（Text-to-Text Transfer Transformer）\cite{t5} は，2019 年に Google が提案した自然言語処理モデルであり，機械翻訳，文書要約，質問応答，文書分類など多岐にわたるタスクにおいて，当時の最高性能（SOTA）を達成した．T5は，BERTのようなエンコーダのみのモデルやGPTのようなデコーダのみのモデルとは異なり，Transformer のエンコーダ・デコーダ構成を採用している．その最大の特徴は，あらゆる自然言語処理タスクを入力テキストを出力テキストに変換するText-to-Text問題として統一的に扱う点にある．

T5 は，C4（Colossal Clean Crawled Corpus）と呼ばれる大規模なクリーニング済みウェブテキストデータセットを用いて事前学習されている．事前学習タスクとしては，BERTのMLMに似たスパン破損（Span-corruption）と呼ばれるタスクが採用されている．これは，入力文中の連続するトークン列（スパン）をランダムにマスクし，デコーダ側でそのマスクされた部分の文字列を生成・復元させるタスクである．これにより，モデルは文脈理解能力とテキスト生成能力を同時に学習することができる．

そして，事前学習した T5 を特定のタスクに適応させるためのファインチューニングにおいても，このText-to-Textの枠組みが一貫して適用される．BERTのように下流タスクに応じて出力層を追加・変更する必要はなく，すべてのタスクで同一のモデル構造と損失関数を使用する．例えば，文書分類タスクであっても，クラスラベルのIDを出力するのではなく，「positive」や「negative」といったラベルのテキストそのものを生成させることで分類を行う．この統一的なアプローチにより，多様なタスクに対して効率的に転移学習を行うことが可能となっている．

本研究では，sonoisa氏が公開しているT5モデルである，Wikipediaの日本語ダンプデータ，OSCAR，CC-100の日本語コーパス（約100GB）を用いて事前学習を行ったT5-base-ver1.1アーキテクチャのモデル\cite{t5}を使用した．

\subsection{gpt-oss-20B}
gpt-oss-20b\cite{gpt-oss}は，2025年8月にOpenAIが公開したオープンウェイトの推論モデルであり ，高度な推論能力を備えている ．本モデルは，GPT-2およびGPT-3のアーキテクチャに基づいた自己回帰的なMixture-of-Experts（MoE）トランスフォーマーであり，総パラメータ数は約20Bである．MXFP4形式への量子化により重みを4.25ビットで表現することで，メモリ使用量を削減し，16GBのメモリを持つシステムでも動作可能という特徴がある．

事前学習には，STEMやコーディング，一般知識に焦点を当てた数兆トークンのテキストデータが用いられており ，化学・生物・放射性物質・核などの有害なコンテンツのフィルタリングも行われている ．事前学習後には，OpenAIo3と同様の思考の連鎖（Chain-of-Thought）を用いた強化学習によってポストトレーニングが行われ，推論能力やツール利用能力が強化されている ．

また，システムプロンプトで「low」「medium」「high」の推論レベルを指定することで，タスクに応じた推論の深さを調整できる機能を有している ．

\section{CoT（chain of thought）}
CoT（Chain-of-Thought Prompting）\cite{CoT}は，2022年にGoogleのWeiらによって提案されたプロンプトエンジニアリングの手法であり，算術推論や常識推論，記号推論など，多段階の推論を必要とする複雑なタスクにおいて，大規模言語モデル（LLM）の性能を飛躍的に向上させることが示されている．CoTは，従来の入力に対して直接的な回答のみを求める標準的なプロンプティングとは異なり，最終的な回答に至るまでの中間的な推論ステップと呼ばれる一連の思考過程をモデルに生成させるという特徴がある．

CoTは，主にFew-shotプロンプティングの枠組みで用いられ，モデルに与える数ショットの例示の中に，質問と回答のペアだけでなく，その回答を導き出すための論理的な思考プロセス（中間的な推論ステップ）を自然言語で記述して含める．これにより，モデルは提示された思考パターンを模倣し，未知の入力に対しても問題を段階的に分解して解くことができるようになる．

\section{Fine-tune-CoT}
Fine-tune-CoT\cite{Fine-turn-CoT}は，KAISTの研究者らによって提案された，大規模言語モデル（LLM）の推論能力を小型モデルに継承させるための学習手法である．従来，複雑な問題を段階的に解くChain-of-Thought（CoT）推論は，パラメータ数が100Bを超える巨大なモデルでのみ発現する創発的能力と考えられてきた．Fine-tune-CoTは，巨大なモデルを教師として利用し，そこから得られた推論過程を生徒である小型モデルに学習させることで，このモデル規模の制約を打破し，小規模パラメータモデルでも高度な推論を可能にすることを目的としている．

この手法のプロセスは，大きく分けて「推論生成」，「精査」，「ファインチューニング」の3つのステップで構成される．まず，GPT-3などの巨大な教師モデルに対し，Zero-shot-CoTプロンプトを用いて，特定の問題に対する中間的な推論ステップと回答を生成させる．次に，教師モデルが導き出した回答が正解と一致するものだけをフィルタリングし，問題を入力，「推論過程＋回答」を出力とする学習用データセットを作成する．これにより，生徒モデルは単に答えを予測するだけでなく，論理的な思考プロセスそのものを模倣するように学習することができる．

Fine-tune-CoTは，巨大モデルへの依存を減らし，実社会のアプリケーションにおいて効率的かつ解釈可能な推論モデルを展開するための重要な道筋を示している．

% % 図の挿入（適宜ファイル名を変更してください）
% \begin{figure}[!ht]
%   \centering
%   \includegraphics[width=0.9\linewidth]{pics/Large_Language_Models_Are_Reasoning_Teachers_cropped.pdf}
%   \caption{本研究におけるCoTデータセット構築フロー}
%   \label{fig:finetune_cot_flow}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{T5モデルによる直接生成手法}
\label{chap:preliminary_experiment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，提案手法の導入に先立ち，日本語データを用いたT5モデルでの直接生成手法（ベースライン）の基本性能を確認するための予備実験について述べる．

\section{実験目的}
Zhangら\cite{gas}は，英語データセットを用いたABSAにおいて，T5モデルを用いた統一的な生成フレームワークであるGAS（Generative Aspect-based Sentiment Analysis）の有効性を示した．
しかし，日本語のアスペクトカテゴリ感情分析タスクにおけるGASの適用事例や，その有効性は十分に検証されていない．
そこで本予備実験では，日本語の楽天トラベルデータセットを用い，GASフレームワークを適用した場合のベースライン精度を明らかにする．この結果を，本研究における提案手法のベースラインとする．
あわせて，レビュー文を入力とする際に，対象文のみを与える場合と，前の文脈情報（Context）を含める場合とで精度にどのような差異が生じるかを検証する．

\section{実験設定}

\subsection{データセットと前処理}
本研究では，楽天グループ株式会社が国立情報学研究所（NII）を通じて提供している\texttt{楽天トラベルデータセット}\cite{rakuten}を使用した．
本コーパスは，12,476件のレビューから文単位に分割された76,624件のレビュー文に対し，以下の7種類のアスペクトカテゴリと，それぞれの感情極性（ポジティブ・ネガティブ）が付与されたマルチラベルデータセットである．

\begin{itemize}
    \item \textbf{アスペクトカテゴリ}: 朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋
    \item \textbf{感情極性}: ポジティブ （$1$），ネガティブ （$0$）
\end{itemize}

データセットのアノテーション例を表\ref{tab:dataset_example}に示す．

\begin{table}[!ht]
    \centering
    \caption{楽天トラベルデータセットのアノテーション例}
    \label{tab:dataset_example}
    \renewcommand{\arraystretch}{1.5} % ラベルの複数行が見やすくなるよう行間を調整
    \small
    % 2列目を p{5.0cm}（標準の左寄せ）に戻しました
    \begin{tabular}{p{9.0cm} p{5.0cm}}
        \toprule
        % 見出しのみ \multicolumn を使って中央揃えに指定
        \multicolumn{1}{c}{\textbf{レビュー文}} & \multicolumn{1}{c}{\textbf{正解ラベル}} \\
        \midrule
        立地はいいと思いますが，トイレにはこばえが数匹いて，朝御飯の味噌汁なんかは具なしでした． & 
        立地:ポジティブ \newline 
        設備・アメニティ:ネガティブ \newline 
        朝食:ネガティブ \\
        \bottomrule
    \end{tabular}
\end{table}

本実験では，全データ（76,624文）に対し，データの質を担保するために以下の基準に基づくフィルタリングを行った．

\begin{itemize}
    \item \textbf{言語および品質による除外}
    
    日本語以外の言語で記述されたデータ，および判読不能なノイズを含むデータを除外した．
    
    \item \textbf{モデル制約による除外}
    
    日本語T5モデルの最大入力長（512トークン）を考慮し，トークナイザによる処理後のトークン数が500を超える長文データを除外した．
    
    \item \textbf{タスク設定による除外}
    
    定義された7つのアスペクトカテゴリのいずれにも該当しない（None）データ，および同一カテゴリに対して相反する感情極性が同時に付与されている矛盾したデータを除外した．
    
    \item \textbf{重複排除}
    
    評価の厳密性を保つため，内容が完全に一致する重複データを除外し，ユニークな事例のみを保持した．
\end{itemize}

上記の前処理を経た有効データは50,406件であった．
本データセットはカテゴリごとのデータ数に偏りがあるため，学習時のバイアスを軽減する目的でダウンサンプリングを行った．
具体的には，可能な限り各カテゴリの分布が均一になるよう調整しつつ，最終的に学習データ20,000件，検証データ2,000件，評価用テストデータ2,000件を抽出した．


\subsection{生成タスクへの変換（ラベル形式）}
本研究では分類問題をテキスト生成問題として扱うため，Zhangら\cite{gas}のExtraction-style（抽出形式）を参考に，教師データのラベル形式を変換した．
具体的には，出力ターゲットを「\texttt{カテゴリ:感情極性}」の形式とし，複数の意見が含まれる場合は垂直バー「\texttt{|}」で連結する形式を採用した．
変換例を表\ref{tab:label_example}に示す．

\begin{table}[h]
    \centering
    \caption{生成タスクにおける入出力データの例}
    \label{tab:label_example}
    \renewcommand{\arraystretch}{1.5} % 項目と内容の視認性を高めるために調整
    \small
    % 1列目を中央揃え，2列目を左揃え（見出しのみ中央）に設定
    \begin{tabular}{>{\centering\arraybackslash}p{2.5cm} p{10.5cm}}
        \toprule
        \textbf{項目} & \multicolumn{1}{c}{\textbf{内容}} \\ 
        \midrule
        \textbf{入力文} & 立地はいいと思いますが，トイレにはこばえが数匹いて，朝御飯の味噌汁なんかは具なしでした． \\ 
        \midrule
        \textbf{出力ラベル} & 立地:ポジティブ \textbar\ 設備・アメニティ:ネガティブ \textbar\ 朝食:ネガティブ \\ 
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{出力の正規化処理}
生成モデルは自由なテキストを出力するため，出力されたアスペクトカテゴリ名に微細な誤字や表記ゆれが含まれる可能性がある．
例えば，「サービス」を「サービ」と出力した場合，これを単純な不一致として扱うとモデルの本来の性能を過小評価する恐れがある．

そこで本実験では，モデルの出力した各用語に対し，編集距離を用いた正規化処理を適用した．

編集距離とは，一方の文字列をもう一方の文字列に変形させるために必要な「挿入」「削除」「置換」の最小操作回数を定義したものである．
\begin{itemize}
    \item \textbf{挿入: 文字を追加する（例：「サービ」 $\rightarrow$ 「サービ\textbf{ス}」）}
    \item \textbf{削除: 文字を取り除く（例：「サービス\textbf{ッ}」 $\rightarrow$ 「サービス」）}
    \item \textbf{置換: 文字を書き換える（例：「サービ\textbf{ズ}」 $\rightarrow$ 「サービ\textbf{ス}」）}
\end{itemize}


具体的には，出力された単語が事前に定義されたアスペクトカテゴリ（朝食，夕食，風呂，サービス，立地，設備・アメニティ，部屋）に含まれない場合，以下の手順で補正を行う．

\begin{enumerate}
    \item 出力語とアスペクトカテゴリ内の各単語との編集距離 $d$ を計算する．
    \item 最も距離が小さい単語を候補とし，その最小距離が $2$ 以下，かつ出力語の長さの半分以下である場合に限り，当該語彙への置き換えを行う．
    \item 上記の条件を満たさない場合は，抽出失敗として扱い，修正は行わない．
\end{enumerate}
この後処理により，生成モデル特有の軽微な文字生成ミスを許容し，本質的な感情分析性能を評価する．

\subsection{モデルおよび学習設定}
本実験におけるモデルの選定および学習時のハイパーパラメータの設定について述べる．

\subsubsection{使用モデル}
本研究では，sonoisa氏が公開しているT5モデルである，\texttt{sonoisa/t5-base-japanese-v1.1}を使用した．このモデルは，T5-base-ver1.1モデルをWikipediaの日本語ダンプデータ，OSCAR，CC-100の日本語コーパスなど約100GBの日本語テキストデータを用いて日本語事前学習を行ったモデルである．

\subsubsection{ハイパーパラメータと学習条件}
モデルの学習における主要な設定値を表\ref{tab:simple_hyperparameters}に示す．

\begin{table}[htbp]
  \centering
  \caption{学習時におけるハイパーパラメータの設定}
  \label{tab:simple_hyperparameters}
  \renewcommand{\arraystretch}{1.3} % 行間を広げて視認性を向上
  \small
  % 両列とも中央揃え（c）に指定
  \begin{tabular}{cc}
    \hline
    \textbf{項目} & \textbf{設定値} \\
    \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 64 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\
    \hline
  \end{tabular}
\end{table}

最大入力トークン数および出力トークン数は，計算リソースと対象とするデータセットの平均長を考慮し，それぞれ 128 および 64 に設定した．最適化アルゴリズムにはAdamWを採用し，学習率を$1.0\times10^{-4}$として固定した．

学習の効率化および過学習の抑制のため，検証データにおけるF1値を監視対象としたアーリーストッピング（Early Stopping）を導入した．具体的には，5 エポック連続で F1 スコアの向上が認められない場合に学習を打ち切るよう設定した．また，各エポック終了時に検証データで最も高い精度を示した時点のモデル重みを，最終的な推論に用いる最良のモデルとして利用した．

また，実験結果の統計的な妥当性を確保するため，シード値として42，100，1000の3通りを設定し，それぞれの条件で独立した学習および評価を行った．本論文で報告する精度評価値は，これら3回の試行によって得られた結果の平均値である．

\subsection{比較手法} 
本研究では，T5モデルへの入力形式がアスペクトカテゴリ感情分類（ACSA）の精度に与える影響を調査するため，以下の2種類の手法を比較・検証する．第一に，評価対象となるレビュー文のみを入力とする手法（以下，直接生成手法），第二に，対象文にその直前の文脈情報を付加して入力する手法（以下，文脈付き直接生成手法）である．

本研究における文脈情報とは，楽天トラベルデータセットにおいて，一つのレビューが文単位で分割・管理されている点を利用し，評価対象文の直前（一つ前のID）に位置する文と定義した．評価対象文がレビューの冒頭である場合など，直前の文が存在しない場合には，文脈情報を「なし」と定義している．文脈情報として複数の文を遡って付与する構成も検討したが，本研究ではT5モデルの最大入力トークン数制限を考慮し，直近の1文のみを採用した．

宿泊レビュー等のユーザー生成コンテンツにおいて，評価対象文は必ずしも一文で意味が完結しているとは限らない．特に，代名詞の指示対象や，前の文脈に依存した評価対象の省略を正確に把握する必要がある．そこで文脈付き直接生成手法では，対象文を\texttt{<}本文\texttt{>}，その直前の文を\texttt{<}文脈文\texttt{>}という特殊タグを用いて構造化し，モデルに明示的に入力する形式を採用した．これにより，モデルが分析対象の範囲を厳密に認識しつつ，周囲の文脈から欠落した情報を補完することで，高精度な判定が可能になると考えられる．

表\ref{tab:Direct-context_example}に，文脈付き直接生成手法における具体的な入出力データの例を示す．本例において，本文の「アメゴの刺身」という記述のみでは，それが朝食と夕食のいずれに対する言及であるかを特定することは困難である．しかし，文脈文に含まれる「夕食」という情報をモデルが参照することで，適切なカテゴリ（夕食）を導出することが可能となる．文脈付き直接生成手法は，このような文脈依存性の高いケースにおける分類精度の向上を主眼としている．

\begin{table}[h]
    \centering
    \caption{文脈付き直接生成手法における入出力データの例}
    \label{tab:Direct-context_example}
    \renewcommand{\arraystretch}{1.5} % 入力が2行になるため，広めの行間を設定
    \small
    % 1列目を中央揃え（p幅指定），2列目を左揃えに設定
    \begin{tabular}{>{\centering\arraybackslash}p{2.5cm} p{10.5cm}}
        \toprule
        \textbf{項目} & \multicolumn{1}{c}{\textbf{内容}} \\ 
        \midrule
        \textbf{入力テキスト} & \texttt{<文脈文>}囲炉裏を前にした夕食は予想以上に最高．\texttt{</文脈文>} \newline
        \texttt{<本文>}特に，アメゴの刺身はとても美味しかったです！\texttt{</本文>} \\ 
        \midrule
        \textbf{出力ラベル} & 夕食:ポジティブ \\ 
        \bottomrule
    \end{tabular}
\end{table}

\subsection{評価指標}
本研究におけるアスペクトカテゴリ感情分類（ACSA）の結果を定量的に評価するため，正解率（accuracy），適合率（Precision），再現率（Recall），F1値（F1-score）の評価指標の4つの指標を用いる．本タスクは一つの文に対して複数のアスペクトカテゴリおよび感情値のペア（例：部屋：ポジティブ，サービス：ネガティブ）を抽出するマルチラベル分類であるため，正解ラベルの集合とモデルの出力集合を比較することで各指標を算出する．なお，算出にあたっては，以下の3つの要素を定義する．

\begin{itemize}\item \textbf{真陽性 （True Positive: TP）}：モデルが予測したアスペクトカテゴリと感情のペアが，正解ラベルに存在する場合．\item \textbf{偽陽性 （False Positive: FP）}：モデルが予測したペアが，正解ラベルに存在しない場合（過剰検出）．\item \textbf{偽陰性 （False Negative: FN）}：正解ラベルに含まれるペアを，モデルが予測できなかった場合（抽出漏れ）．
\end{itemize}

\subsubsection{正解率 （Accuracy）}正解率は，全テストデータのうち，モデルの出力したカテゴリおよび感情のペアが，正解ラベルと完全に一致したデータの割合を示す．本研究のようなマルチラベルタスクにおいては，全てのラベルが一致した場合のみを正解とする．全体の分類性能を直感的に把握するために用いるが，一部のカテゴリのみを正解した場合が評価されないため，後述の適合率や再現率と併せて考察する必要がある．

\subsubsection{適合率 （Precision）}適合率は，モデルが「正解」と予測した全ペアのうち，実際に正解ラベルに含まれていたペアの割合を示す．以下の式で定義される．
\[\text{Precision} = \frac{\text {TP}}{\text {TP} + \text {FP}}\]
本指標が高いことは，モデルが「根拠のない誤った評価」や「存在しないカテゴリ」を不必要に過剰検出していないことを意味し，出力結果の信頼性を表す．
\subsubsection{再現率 （Recall）}再現率は，正解ラベルに含まれる全ペアのうち，モデルが正しく予測できたペアの割合を示す．以下の式で定義される．
\[\text{Recall} = \frac{\text {TP}}{\text {TP} + \text {FN}}\]
本指標が高いことは，レビュー文に含まれる多様な評価項目を抽出漏れなく抽出できていることを意味する．

\subsubsection{F1値（F1-score）}F1値は，適合率と再現率の調和平均であり，以下の式で定義される．
\[F1 = \frac{2 \cdot \text {Precision} \cdot \text {Recall}}{\text {Precision} + \text {Recall}}\]
適合率と再現率はトレードオフの関係にあることが多いため，これらを統合したF1値を用いることで，モデルの総合的な抽出・分類性能を評価する．本研究における各手法の優劣を判断する主要な指標として採用する．

\section{実験結果}
実験結果を表\ref{tab:baseline_overall}および表\ref{tab:baseline_category_f1}に示す．
表\ref{tab:baseline_overall}は先の章で述べた4つの評価指標での比較を示している．また，表\ref{tab:baseline_category_f1}はアスペクトカテゴリごとに分けた際のF1値の比較を示す．
\begin{table}[!ht]
  \centering
  \caption{ベースラインモデルの性能比較（3回の試行による平均 $\pm$ 標準偏差）}
  \label{tab:baseline_overall}
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    直接生成   & $0.894 \pm 0.003$ & $0.745 \pm 0.014$ & $0.813 \pm 0.008$ & $0.624 \pm 0.010$ \\
    文脈付き直接生成  & $\textbf{0.903} \pm \textbf{0.004}$ & $\textbf{0.760} \pm \textbf{0.005}$ & $\textbf{0.825} \pm \textbf{0.003}$ & $\textbf{0.643} \pm \textbf{0.004}$ \\ \bottomrule
  \end{tabular}
\end{table}

\begin{table}[!ht]
  \centering
  \caption{アスペクトカテゴリごとのF1値の比較}
  \label{tab:baseline_category_f1}
  \begin{tabular}{lcc} \toprule
    アスペクトカテゴリ & 直接生成 & 文脈付き直接生成 \\ \midrule
    風呂               & $0.854$ & $\textbf{0.864}$ \\
    夕食               & $\textbf{0.854}$ & $0.845$ \\
    立地               & $0.842$ & $\textbf{0.850}$ \\
    部屋               & $0.818$ & $\textbf{0.830}$ \\
    朝食               & $0.817$ & $\textbf{0.825}$ \\
    設備・アメニティ   & $0.777$ & $\textbf{0.802}$ \\
    サービス  & $0.721$ & $\textbf{0.761}$ \\ \bottomrule
  \end{tabular}
\end{table}

\section{考察と課題}
\subsection{考察}
実験結果より，文脈情報を付与した文脈付き直接生成手法は，レビュー文のみを用いる直接生成手法と比較して，4つの評価指標すべてにおいて上回る結果となった．
特に，総合的な性能を示すF1値では $0.012$ ポイントの向上が確認された．また，アスペクトカテゴリごとの比較においても，夕食カテゴリを除くほぼすべての項目で精度が向上している．
この結果は，楽天トラベルのようなレビューデータにおいて，代名詞の指示対象や，文脈に依存して省略された評価対象を正確に捉える上で，前後の文脈情報が一定の有効性を持つことを示唆している．
しかし，その向上幅は限定的であり，単純な文脈の連結だけでは解決できない課題が残されていることも明らかとなった．

\subsection{課題分析}
本実験の結果から明らかになった日本語データにおけるACSAにおける課題は，主に以下の2点に集約される．

第一に，再現率（Recall）の低さである．
両手法ともに，適合率（Precision）が $0.90$ 前後と高い水準にあるのに対し，再現率は $0.75$ 前後と約 $0.15$ ポイントもの乖離が見られた．
これは，モデルが抽出したペアの正答率は高いものの，本来抽出すべきアスペクトと感情極性のペアを数多く見逃している（抽出漏れが多い）ことを意味する．

第二に，文中に含まれる暗示的なアスペクトカテゴリへの対応である．
カテゴリ別のF1値において，「サービス」カテゴリのスコアが他と比較して顕著に低い結果となった．
エラー分析の結果，「サービス」に関する評価は，「朝食」や「部屋」のように具体的な単語が明示されることが少なく，「待たされた」「気が利かない」といった文脈から読み取る必要がある暗示的な表現が大半を占めることが分かった．従来の単純なGASでは，このような表層的な単語に依存しない表現を十分に捉えきれていないと考えられる．

\subsection{次章への展望}
上記の問題を解決するためには，人間が無意識に行っている「待たされた $\rightarrow$ 対応が遅い $\rightarrow$ サービスはネガティブ」といった論理的な推論ステップをモデルに学習させる必要がある．

そこで次章では，T5モデルにACSAの中間推論プロセスを出力させる提案手法について述べる．
推論過程を明示的に扱わせることで，文中に含まれる暗示的なアスペクトカテゴリの抽出能力を向上させ，抽出漏れ（Recallの低さ）の改善を目指す．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Fine-tune-CoTを用いた推論過程の導入}
\label{chap:proposed_method}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本章では，前章で明らかになった課題である「再現率の低さ」および「暗示的アスペクトカテゴリの抽出漏れ」を解決するための提案手法について述べる．

\section{手法の概要}
\label{sec:method_overview}

本研究では，ACSAタスクにおいて中間推論プロセス（CoT）をモデルに学習させるため，Hoら\cite{Fine-turn-CoT}が提案した\textbf{Fine-tune-CoT}の枠組みを採用する．
これは2章で述べた通り，大規模言語モデル（教師モデル）が持つ高度な推論能力を，小型モデル（生徒モデル）に継承させるための学習手法である．

本研究におけるプロセスは，以下の3ステップで構成される．

\begin{enumerate}
    \item \textbf{推論設計}:
    本タスクに適した構造化された推論フォーマットを定義する（4.2節）．
    
    \item \textbf{データ構築}:
    教師モデル（gpt-oss-20B）に推論を生成させ，厳格なフィルタリングを経てCoTデータセットを作成する（4.3節）．
    
    \item \textbf{ファインチューニング}:
    作成したデータセットを用いて生徒モデル（T5）を学習させる．
\end{enumerate}

\section{中間推論の形式設計}
\label{sec:reasoning_formats}
一般的なCoT（Zero-shot-CoTなど）では「Step-by-stepで考えて」といった指示により多様な自然言語による推論を生成させるが，本研究で用いるT5のような小規模モデルにとって，自由度の高すぎるテキストは学習の収束を妨げるノイズとなり得る．そこで本研究では，T5モデルが得意とする変換タスクに落とし込むため，厳密に構造化された以下の2つの推論パターンを考案した．

\subsection{パターン1：用語起点型}
用語起点型は，従来のACSAタスクの処理フロー（アスペクト用語抽出 $\rightarrow$ アスペクトカテゴリ分類 $\rightarrow$ 感情分類）をCoTとして言語化した形式である．
文中に明示されている評価対象語（アスペクト用語）を起点として推論を展開するため，評価対象語が明確なケースにおいて高い適合率が期待できる．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 用語抽出] 文中から評価対象となっている語句をすべて抽出する．
        \item[STEP2 カテゴリ分類] 抽出した各用語が，7つのアスペクトカテゴリのどれに該当するかを分類する．
        \item[STEP3 感情分析] アスペクトカテゴリごとに，対応する用語周辺の表現から極性を判定する．
        \item[STEP4 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応．\\
\textbf{CoT出力}:\\
\texttt{<STEP1> レストランスタッフ | 対応}\\
\texttt{<STEP2> レストランスタッフ $\rightarrow$ サービス | 対応 $\rightarrow$ サービス}\\
\texttt{<STEP3> サービス $\rightarrow$ 一番よかった $\rightarrow$ ポジティブ}\\
\texttt{<STEP4> サービス:ポジティブ}
\end{minipage}}

\subsection{パターン2：カテゴリ点検型}
カテゴリ点検型は文中の単語に依存せず，事前に定義された7つのアスペクトカテゴリすべてについて「言及があるか？」を順次点検するロジックを採用している．これにより，具体的なアスペクト用語が存在しない場合でも，文脈からの推論を促すことを狙いとしている．

\begin{itemize}
    \item \textbf{推論ステップ}:
    \begin{description}
        \item[STEP1 全カテゴリ点検] 7つのアスペクトカテゴリすべてに対し，有無とその根拠（該当箇所または文脈）を列挙する．
        \item[STEP2 感情分析] 「あり」と判定されたアスペクトカテゴリについてのみ，感情極性を判定する．
        \item[STEP3 回答] 最終的なラベルを出力する．
    \end{description}
\end{itemize}

\textbf{生成例}: \\
\fbox{\begin{minipage}{0.9\textwidth}
\small
\textbf{入力文}: 一番よかったのはレストランスタッフさんの対応．\\
\textbf{CoT出力}:\\
\texttt{<STEP1>}\\
\texttt{- サービス: あり （根拠: レストランスタッフさんの対応）}\\
\texttt{- 夕食: なし}\\
\texttt{- 朝食: なし}\\
\texttt{- 立地: なし}\\
\dots （中略） \dots\\
\texttt{<STEP2>}\\
\texttt{- サービス: レストランスタッフさんの対応 $\rightarrow$ ポジティブ}\\
\texttt{<STEP3> サービス:ポジティブ}
\end{minipage}}

\section{CoTデータの構築プロセス}
\label{sec:cot_generation}

前節で定義した推論形式に基づき，学習用データセット（楽天トラベルレビュー）に対して中間推論付きデータを生成・拡張した．生成に利用した学習データは4章で利用した学習データと同様のデータを利用している．具体的な手順は以下の通りである．

\subsection{プロンプトによる推論生成}
教師モデル（gpt-oss-20B\cite{gpt-oss}）に対し，レビュー文と文脈情報を入力し，CoTの生成を行った．
この際，プロンプトには各パターンの出力フォーマット定義と，数件のFew-shot事例（入力と理想的なCoT出力のペア）を含めることで，教師モデルに対し指定した構造での出力を強制した．

生成時における教師モデルのハイパーパラメータ設定を表\ref{tab:teacher_hyperparameters}に示す．推論の多様性と論理的整合性のバランスを考慮し，Temperatureは低めに設定した．生成にまた，用いた具体的なプロンプトの全文は，付録に記す．
\begin{table}[htbp]
  \centering
  \caption{CoTデータ生成時における教師モデルの設定}
  \label{tab:teacher_hyperparameters}
  \renewcommand{\arraystretch}{1.2}
  \small
  \begin{tabular}{ll} \hline
    \multicolumn{1}{c}{\textbf{項目}} & \multicolumn{1}{c}{\textbf{設定値}} \\ \hline \hline
    利用モデル & openai/gpt-oss-20b \\
    推論レベル & medium \\
    最大生成トークン数 （Max tokens） & 4,096 \\
    Temperature & 0.2 \\
    Repetition penalty & 1.1 \\
    コンテキスト長 （Context length） & 8,192 \\\hline
  \end{tabular}
\end{table}


\subsection{データの精査}
教師モデルは常に正しい推論を行うとは限らないため，誤った推論（ハルシネーション）を含むデータが生徒モデルの学習に悪影響を与えないよう，以下の厳格なフィルタリング処理を行った．

\begin{enumerate}
    \item \textbf{回答の一致確認}: 
    教師モデルが生成した最終回答（STEP3またはSTEP4）が，元のデータセットの正解ラベルと完全に一致するかを確認する．
    \item \textbf{形式の整合性確認}: 
    生成された推論過程が，指定した構造（\texttt{<}STEP\texttt{>}タグやカテゴリ順序）を遵守しているかを確認する．
\end{enumerate}

上記の条件を全て満たしたデータのみをCoTデータセットとして採用し，条件を満たさないデータについては人手による修正または再生成を行った．
これにより，論理的整合性と品質が担保された学習データセットを構築した．

% 図の挿入（適宜ファイル名を変更してください）
\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\linewidth]{pics/Fine-tune-CoT_cropped.pdf}
  \caption{本研究におけるCoTデータセット構築フロー}
  \label{fig:finetune_cot_flow}
\end{figure}

\section{損失関数の設計}
\label{sec:loss_calculation_details}

本研究では，モデルの学習において論理的な推論（reasning）と最終的な回答（answer）のどちらを重視するかを制御するため，動的な重み付け損失関数を導入した．
具体的な計算プロセスは以下の3段階で構成される．

\subsubsection{1. ラベル系列の分離とマスキング}
学習データに含まれる正解トークン列 $Y$ を，特定のマーカー（用語起点型では\texttt{<STEP4>}，カテゴリ点検型では\texttt{<STEP3>}）を境界として，思考過程部分 $Y_{rea}$ と最終回答部分 $Y_{ans}$ に論理的に分離する．
実装上は，以下のようなマスク処理を行うことで2つのラベル系列を生成した．

\begin{itemize}
    \item \textbf{推論ラベル （$Y'_{rea}$）}: 系列内の最終回答部分をパディング（Mask）し，思考過程のみを損失計算の対象とする．
    \item \textbf{回答ラベル （$Y'_{ans}$）}: 系列内の思考過程部分をパディング（Mask）し，最終回答のみを損失計算の対象とする．
\end{itemize}

\subsubsection{2. 個別損失の計算}
分離した各ラベル系列に対し，標準的なクロスエントロピー誤差を用いて個別の損失を計算する．

\begin{equation}
    \mathcal{L}_{rea} = \text{CrossEntropy}（M（X）, Y'_{rea}）
\end{equation}
\begin{equation}
    \mathcal{L}_{ans} = \text{CrossEntropy}（M（X）, Y'_{ans}）
\end{equation}

ここで，$M（X）$ はモデルの出力分布を表す．
$\mathcal{L}_{rea}$ は論理構造の学習を担当し，$\mathcal{L}_{ans}$ は最終出力の精度を担当する．

\subsubsection{3. 重み付き統合損失の算出}
最終的な損失関数 $\mathcal{L}_{total}$ は，ハイパーパラメータ $\alpha$ （$0 \le \alpha \le 1$） を用いて，上記2つの損失の加重和として定義される．

\begin{equation}
    \mathcal{L}_{total} = \alpha \cdot \mathcal{L}_{rea} + （1 - \alpha） \cdot \mathcal{L}_{ans}
\end{equation}

ここで，$\alpha$ は思考過程に対する重みを表す．
$\alpha$ を $1.0$ に近づけると，モデルは推論過程の再現を重視して学習し，逆に $0.0$ に近づけると，推論過程の整合性よりも最終的な正解ラベルの出力を最優先するように学習が進む．
本実験では，この $\alpha$ を調整することで，推論と回答の最適なトレードオフを探索する．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{評価実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{実験目的}
本実験の目的は，日本語の楽天トラベルデータセットを用い，アスペクトカテゴリ感情分析（ACSA）における提案手法の有効性を多角的に検証することである．具体的には，手法間の精度比較といった定量分析に加えて，実際の出力の定性分析を行う．

第4章の実験において最も高精度であった文脈付き直接生成手法をベースラインとし，提案手法である中間推論を学習させる用語起点型CoTおよびカテゴリ点検型CoTの計3手法について，T5モデルを用いた性能評価を行う．さらに，学習戦略の違いによる影響を検証するため，前節で設計した推論過程と回答部分の重みを調整する重み付き損失計算と，すべてのトークンを一様に学習させる通常の損失計算（以下，Normal）との比較も行う．

\section{実験設定}
\label{sec:exp_settings_cot}
\subsection{モデルおよびハイパーパラメータ}
使用するデータセット，評価指標，編集距離を考慮した正解判定基準などは，第4章と同様であるため，ここでの再掲は省略する．

ただし，提案手法では中間推論（CoT）を含む長いテキスト系列を生成する必要があるため，モデルの最大出力トークン数を従来の128トークンから400トークンへと拡張した．
提案手法における学習時のハイパーパラメータを表\ref{tab:CoT_hyperparameters}に示す．

\begin{table}[htbp]
  \centering
  \caption{提案手法における学習時のハイパーパラメータ}
  \label{tab:CoT_hyperparameters}
  \begin{tabular}{cc} \hline
    項目 & 設定値 \\ \hline \hline
    最大入力トークン数 & 150 \\
    最大出力トークン数 & 400 \\
    バッチサイズ & 8 \\
    最大エポック数 & 20 \\
    学習率 & $1.0 \times 10^{-4}$ \\
    最適化アルゴリズム & AdamW \\
    Early Stopping & 5 エポック \\ \hline
  \end{tabular}
\end{table}

\subsection{学習戦略の比較設定}
前節で定義した損失関数における重みパラメータ $\alpha$ が，モデルの推論能力と回答精度に与える影響を検証するため，以下の4つの設定で比較実験を行う．

\begin{itemize}
    \item Normal: 
    トークンごとの重み付けを行わない標準的な設定（$\alpha$ を適用しない，すなわち全てのトークンを一様に学習する）．
    \item \textbf{$\alpha \in \{0.2, 0.5, 0.8\}$}: 
    中間推論部（reasoning）と回答部（answer）の学習比率を調整する設定．
    \begin{itemize}
        \item $\alpha=0.2$: 回答部を重視（推論の重み $0.2$, 回答の重み $0.8$）
        \item $\alpha=0.5$: 推論と回答を均等に学習
        \item $\alpha=0.8$: 推論部を重視（推論の重み $0.8$, 回答の重み $0.2$）
    \end{itemize}
\end{itemize}

これらの比較により，モデルにとって中間推論プロセスと最終回答のどちらを重点的に学習させることが全体の性能向上（F1値等）に寄与するか，そのトレードオフを明らかにする．
\section{実験結果}
% 本実験に先立ち，CoTモデルの学習における損失関数の重みパラメータ $\alpha$ の最適化を行った．
% 検証の結果，用語起点型CoTでは $\alpha=0.5$，カテゴリ点検型CoTでは重み付けを行わない（Normal）設定において，それぞれ最も高いF1値が得られた．
% したがって，以下の性能比較では，各手法におけるこれらの最良設定を用いた結果を示す．
本研究の主実験に先立ち，中間推論の学習バランスを制御する損失関数の重みパラメータ $\alpha$ の最適化を行った。その結果を表 \ref{tab:alpha_comparison} に示す。検証の結果，用語起点型CoTでは $\alpha=0.5$，カテゴリ点検型CoTでは重み付けを行わないNormal設定において，それぞれ最高のF1値を記録した。これを受け，以降の性能比較では，各手法において得られたこれらの最適設定の結果を報告する。

\begin{table}[!ht]
    \centering
    \caption{学習戦略によるF1値の比較}
    \label{tab:alpha_comparison}
    \begin{tabular}{lcc} \toprule
        学習戦略 & 用語起点型CoT & カテゴリ点検型CoT \\ \midrule
        Normal & $0.830 \pm 0.004$ & $\textbf{0.863} \pm \textbf{0.002}$ \\
        $\alpha = 0.2$ & $0.829 \pm 0.006$ & $0.861 \pm 0.005$ \\
        $\alpha = 0.5$ & $\textbf{0.832} \pm \textbf{0.005}$ & $0.859 \pm 0.004$ \\
        $\alpha = 0.8$ & $0.829 \pm 0.003$ & $0.836 \pm 0.005$ \\ \bottomrule
    \end{tabular}
\end{table} 

\begin{table}[!ht]
  \centering
  \caption{提案手法とベースラインの性能比較（各手法の最良設定における平均 $\pm$ 標準偏差）}
  \label{tab:best_model_comparison}
  \small % 少し文字を小さくして収まりを良くする
  \begin{tabular}{lcccc} \toprule
    手法 & Precision & Recall & F1-score & Accuracy \\ \midrule
    文脈付き直接生成 & $\textbf{0.903} \pm \textbf{0.004}$ & $0.760 \pm 0.005$ & $0.825 \pm 0.003$ & $0.643 \pm 0.004$ \\
    用語起点型CoT & $0.856 \pm 0.002$ & $0.810 \pm 0.009$ & $0.832 \pm 0.005$ & $0.653 \pm 0.003$ \\
    \textbf{カテゴリ点検型CoT} & $0.893 \pm 0.004$ & $\textbf{0.835} \pm \textbf{0.006}$ & $\textbf{0.863} \pm \textbf{0.002}$ & $\textbf{0.700} \pm \textbf{0.001}$ \\ \bottomrule
  \end{tabular}
  \\ \vspace{1mm}
  \footnotesize ※用語起点型: $\alpha=0.5$, カテゴリ点検型: Normal
\end{table}

\begin{table}[!ht]
  \centering
  \caption{アスペクトカテゴリごとのF1値比較（最良モデル）}
  \label{tab:best_category_comparison}
  \small
  \begin{tabular}{lccc} \toprule
    アスペクトカテゴリ & 文脈付き直接生成 & 用語起点型 & \textbf{カテゴリ点検型} \\ \midrule
    夕食              & $0.845$ & $0.878$ & $\textbf{0.902}$ \\
    風呂              & $0.864$ & $0.879$ & $\textbf{0.897}$ \\
    立地              & $0.850$ & $0.858$ & $\textbf{0.886}$ \\
    朝食              & $0.825$ & $0.849$ & $\textbf{0.871}$ \\
    部屋              & $0.830$ & $0.826$ & $\textbf{0.851}$ \\
    サービス & $0.761$ & $0.751$ & $\textbf{0.836}$ \\
    設備・アメニティ  & $\textbf{0.802}$ & $0.780$ & $0.794$ \\ \bottomrule
  \end{tabular}
\end{table}

\begin{table}[tb]
  \centering
  \caption{手法別エラータイプの発生件数比較（3回の平均）}
  \label{tab:error_comparison}
  \small
  \begin{tabular}{lcccc} \toprule
    手法 & Hallucination & Missed & Sentiment Error & Other Error \\ \midrule
    文脈付き直接生成       & $145.0$ & $413.7$ & $36.7$ & $118.3$ \\
    用語起点型CoT & $179.3$ & $344.7$ & $\textbf{33.3}$ & $136.3$ \\
    \textbf{カテゴリ点検型CoT} & $\textbf{144.3}$ & $\textbf{293.3}$ & $40.7$ & $121.3$ \\ \bottomrule
  \end{tabular}
  \footnotesize
  \\ \vspace{1mm}
  ※ Hallucination: 過剰検出（適合率低下の要因）, Missed: 抽出漏れ（再現率低下の要因）
\end{table}

\section{分析・考察}
\subsection{定量分析・考察}
\subsubsection{手法ごとの精度比較}
表\ref{tab:best_model_comparison}に示す通り，文脈付き直接生成手法，用語起点型CoT手法，カテゴリ点検型CoT手法の3手法を比較すると，提案手法であるカテゴリ点検型CoT手法がF1値および正解率において他手法を大きく上回る性能を示した．
特に着目すべき点は，CoTの導入目的の一つである再現率（Recall）の向上である．
カテゴリ点検型は，ベースラインと比較して再現率が $0.075$ ポイントと大幅に上昇しており，この抽出漏れの改善がF1値と正解率の向上に直接的に寄与したと考えられる．
一方で，用語起点型CoTもベースライン比で再現率が $0.05$ ポイント上昇しているものの，その代償として適合率（Precision）が $0.047$ ポイント低下するトレードオフが発生している．その結果，最終的なF1値と正解率は微増に留まった．
これに対し，カテゴリ点検型は適合率の低下を最小限（ベースラインと同等水準）に抑えつつ，再現率のみを大幅に引き上げることに成功しており，理想的な精度向上を達成している．

次に，表\ref{tab:best_category_comparison}を用いてアスペクトカテゴリごとの詳細を分析する．
カテゴリ点検型CoT手法は，「設備・アメニティ」カテゴリを除くすべてのカテゴリにおいてベースラインを上回るF1値を記録した．
特に，課題とされていた「サービス」カテゴリにおいては $0.836$ という高いスコアを達成している．これは，ベースラインと比較して顕著な改善であり，カテゴリ点検型の推論プロセスが，暗示的なアスペクトカテゴリ表現の抽出に有効であることを強く示唆している．
また，その他の明示的なカテゴリにおいても安定した向上が確認されたことから，本手法はレビューの表現の形式にかかわらず，アスペクトカテゴリの見逃しを包括的に削減可能であると考えられる．

\subsubsection{エラー傾向の分析}
表\ref{tab:error_comparison}のエラー発生数（3試行平均）に基づき，特に抽出漏れと過剰検出について考察する．

第一に抽出漏れ（Missed）について，カテゴリ点検型CoTはベースライン比約30\%減（$413.7 \to 293.3$件）という大幅な改善を達成した．用語起点型（$344.7$件）も減少傾向にあるが，全カテゴリを網羅的に走査する点検型の方が，暗示的表現の捕捉において優位性を示した．

第二に過剰検出（Hallucination）について，一般に再現率向上は適合率低下（過剰検出の増加）を招くトレードオフがある．実際，用語起点型はこの影響で過剰検出が増加（$145.0 \to 179.3$件）したが，カテゴリ点検型はベースライン同等（$144.3$件）の水準を維持した．

以上より，カテゴリ点検型CoTは単に抽出数を増やすのではなく，誤検出を抑えつつ見落としのみを最小化するという，推論を実現していると考えられる．


\subsubsection{学習戦略による精度比較}
表\ref{tab:alpha_comparison}に，学習戦略の違いによるF1値を示す．
結果として，損失関数の重み付けによる精度の改善効果は限定的であることが明らかとなった．
用語起点型CoTでは $\alpha=0.5$ の設定でF1値が最大となったが，重み付けなし設定（Normal）との差は微小である．
一方，カテゴリ点検型CoTにおいては，重み付けなし設定（Normal）が最も高い精度を示し，次点で $\alpha=0.2$ （中間推論重視）の設定が続いた．
特筆すべきは，$\alpha$ を大きく設定し，モデルに回答の生成を重視させるほど，逆に精度が低下している点である．
この傾向は，正しい最終回答を導き出すためには，その過程である「中間推論」の生成を軽視してはならず，推論プロセスを十分に学習させることが不可欠であることを裏付けている．
したがって，カテゴリ点検型においては，人為的な重み付けを行うよりも，モデルが自然に推論と回答を学習する重み付けなし設定が，点検ロジックの特性を最も活かせる設定であると結論付けられる．

\subsection{定性分析・考察}
\subsubsection{暗示的アスペクトの抽出成功事例}
表\ref{tab:qualitative_case_study}に，本実験における各手法の出力結果の一例を示す．
本事例の入力文には，「スタッフ」などの「サービス」カテゴリを直接示唆する明示的なアスペクト語が存在しない．

その結果，文脈付き直接生成手法では，「夕食」は抽出できたものの，文脈に含まれない「朝食」を誤って出力し，かつ肝心の「サービス」カテゴリに関しては抽出漏れが発生している．

また，用語起点型CoTにおいては，「バイキング」という単語から「夕食」への分類は成功しているが，「会場」や「待たされた」という記述を物理的な設備への不満と解釈し，「設備・アメニティ」カテゴリへの誤分類を起こしている．

対して，カテゴリ点検型CoTは，STEP1の点検プロセスにおいて，「10分以上待ちました」という事象を根拠として「サービス」カテゴリへ正しく対応付けている．
これは，単語の表面的な情報のみに依存せず，「待たされる $\rightarrow$ サービスの問題」という論理的な推論が正常に機能した結果であり，暗示的な表現に対するカテゴリ点検型の優位性を裏付けるものであると考えられる．
\begin{table}[!ht]
    \centering
    \caption{暗示的表現を含む事例における中間推論プロセスの比較}
    \label{tab:qualitative_case_study}
    \renewcommand{\arraystretch}{1.2} % 行間調整
    \footnotesize % 文字サイズを少し小さくして収まりを良くする
    % 列幅を調整 （合計がtextwidthを超えないように注意）
    \begin{tabular}{|p{2.5cm}|p{12.0cm}|}
        \hline
        \multicolumn{2}{|c|}{\textbf{事例情報}} \\
        \hline
        \textbf{入力文} & \texttt{<文脈文>}一番の問題は，食事です．（特に夕食）\texttt{</文脈文>} \newline \texttt{<本文>}まず，バイキングの会場に入るまでに10分以上待ちました．\texttt{</本文>} \\
        \hline
        \textbf{正解ラベル} & \textbf{サービス:ネガティブ} \textbar\ 夕食:ネガティブ \\
        \hline
        \hline
        \multicolumn{2}{|c|}{\textbf{モデル出力の比較}} \\
        \hline
        \textbf{文脈付き直接生成} & 夕食:ネガティブ \textbar\ 朝食:ネガティブ \newline 
        $\rightarrow$ \textcolor{red}{$\times$ 「サービス」の抽出漏れ（Missed）および「朝食」の誤検知} \\
        \hline
        \textbf{用語起点型} & 
        \texttt{<STEP1>} バイキング \textbar\ 会場 \textbar\ 10分以上待ちました \newline
        \texttt{<STEP2>} バイキング$\rightarrow$夕食 \textbar\ 会場$\rightarrow$設備・アメニティ \textbar\ 10分以上待ちました$\rightarrow$設備・アメニティ \newline
        \texttt{<STEP3>} 夕食$\rightarrow$10分以上待ちました$\rightarrow$ネガティブ \textbar\ 設備・アメニティ$\rightarrow$10分以上待ちました$\rightarrow$ネガティブ \newline
        \texttt{<STEP4>} 夕食:ネガティブ \textbar\ \textbf{設備・アメニティ:ネガティブ} \newline
        $\rightarrow$ \textcolor{red}{$\times$ 「会場」を用語ベースで推論し，設備への不満と誤認} \\
        \hline
        \textbf{カテゴリ点検型} & 
        \texttt{<STEP1>} \newline
        - \textbf{サービス:あり（根拠:10分以上待ちました）} \newline
        - 夕食:あり（根拠:バイキングの会場に入るまでに10分以上待ちました） \newline
        - 朝食:なし \newline
        - 立地:なし \newline
        - 設備・アメニティ:なし \newline
        - 部屋:なし \newline
        - 風呂:なし \newline
        \texttt{<STEP2>} \newline
        - サービス:10分以上待ちました$\rightarrow$ネガティブ \newline
        - 夕食:バイキングの会場に入るまでに10分以上待ちました$\rightarrow$ネガティブ \newline
        \texttt{<STEP3>} \textbf{サービス:ネガティブ \textbar\ 夕食:ネガティブ} \newline
        $\rightarrow$ \textcolor{blue}{$\bigcirc$ 全カテゴリ点検により文脈から「サービス」を抽出成功} \\
        \hline
    \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結論}
\label{chap:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{まとめ}
本研究では，アスペクトカテゴリ感情分析において，予備実験として行った直接生成手法から見つかった暗示的なアスペクトカテゴリ表現の抽出精度向上と再現率の向上を目的とし，大規模言語モデルの推論能力を中間推論として導入する手法について検証を行った．特に，人間がレビューを解釈する際の論理プロセスを模倣するため，用語起点型CoTとカテゴリ点検型CoTの2つの推論形式を設計・比較した．

実験の結果，カテゴリ点検型CoTは，ベースライン手法（文脈付き直接生成手法）と比較してF1値を大幅に向上させた．
本研究の成果は，ベースラインが苦手としていた暗示的な表現が多いサービスカテゴリのF1値精度を大幅に上昇させ，再現率（Recall）において $0.075$ ポイントという劇的な改善を達成しつつ，適合率（Precision）の低下を抑制できた点である．
また，定性分析においても，「待たされた」といったアスペクト語を含まない記述に対し，文脈から論理的に「サービス」カテゴリを導き出す様子が確認された．

以上の結果より，アスペクトカテゴリ感情分析タスクにおいては，表層的な単語の出現に依存する抽出のアプローチよりも，推論過程において全カテゴリを強制的に点検するのアプローチが極めて有効であり，日本語データにおけるアスペクトカテゴリ感情分析において強力な手段となると結論付ける．

\section{今後の展望}
本研究の成果を発展させるため，以下の課題が今後の展望として挙げられる．

第一に，カテゴリ定義の境界における曖昧性の解消である．
エラー分析の結果，「大浴場の廊下（風呂か設備か）」のように，人間でも判断が分かれるような事例において誤分類が発生していた．これを解決するためには，学習データのラベルの調整や推論ステップにおいて，カテゴリの包含関係や定義をより厳密にモデルへ教示する設計が必要と考えられる．

第二に，他ドメインへの汎用性の検証である．
本実験では宿泊施設のレビューを用いたが，製品レビューや飲食店レビューなど，他のドメインにおいても「カテゴリ点検型」のアプローチが有効であるか検証する必要がある．特に，カテゴリ数が数十個に及ぶような多クラス分類タスクにおいても点検型のアプローチが有効であるかなどは興味深い研究課題である．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 謝辞
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{謝辞}
本研究を進めるにあたり，多大なる支援と丁寧なご指導をいただいた岐阜大学工学部電気電子・情報工学科情報コースの松本忠博准教授に，深く感謝を申し上げます．また，日頃より活発な議論を行い，有益な助言をいただいた研究室の皆様に心より感謝申し上げます．

本研究には，国立情報学研究所（NII）のIDRデータセット提供サービスを介して楽天グループ株式会社から提供を受けた「楽天トラベルレビュー：アスペクト・センチメントタグ付きコーパス」\cite{rakuten}を利用いたしました．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{junsrt}  
\bibliography{ref}         

\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{付録}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
本研究で使用したカテゴリ点検型CoT，用語起点型CoTの生成プロンプトを以下に示す．

\begin{tcolorbox}[title=カテゴリ点検型CoT生成プロンプト, fonttitle=\bfseries]
\small
\begin{verbatim}
あなたはレビュー分析の専門家です。提供された「正解ラベル」が正しいことを前提とし、正解ラベルを正当化するための逆算型推論を生成してください。

【重要ルール】
1. 逆算型推論の厳守:分析対象は「正解ラベルに含まれるカテゴリのみ」とする。
2. 証拠主義:根拠は必ず「レビュー文」に存在する表現のみを使用する。
3. 出力形式の固定:前置き・補足説明・コメントは一切出力せず、出力は必ず <STEP1>から<STEP3> の順で記述する。

【分析ステップ定義】
<STEP1> カテゴリ別スキャン:
- 7つのカテゴリ（サービス, 夕食, 朝食, 立地, 設備・アメニティ, 部屋, 風呂）すべてについて記述すること
- 各カテゴリについて「あり・なし」を判定し、根拠を文中から抜き出し示す。
- サービス、スタッフ等の語がなくても、体験的表現（助かった、対応してくれた等）を根拠としてよい。
- 全体評価:具体的記述がないカテゴリは、最高でした・全般的に満足等の全体評価を割り当ててよい。
‐ レビュー全体を根拠として使用する場合は[全体]とする。

<STEP2> 感情判定:
- 各カテゴリが正解ラベルの感情値になる理由を簡潔に示す。
- 根拠と感情極性を短く対応付ける。
- 要望・改善希望（〜してほしい等）はネガティブと判定する。
‐ レビュー全体を根拠として使用する場合は[全体]とする。

<STEP3> 最終出力:
- 正解ラベルと完全に一致する形式で出力する。
- 並び順・表記・区切りを含め、正解ラベルを一字一句変更しない。

【参考例（必ず同一形式で模倣せよ）】
～
\end{verbatim}
\end{tcolorbox}

\begin{tcolorbox}[title=用語起点型CoT生成プロンプト, fonttitle=\bfseries]
\small
\begin{verbatim}
あなたはレビュー分析の専門家です。提供された「正解ラベル」が正しいことを前提とし、その判定根拠となる論理プロセスをレビュー文から逆算して生成してください。

【重要ルール】
1. 探索範囲の限定:分析対象は「正解ラベルに含まれているカテゴリ」のみとする。
2. 証拠主義:根拠は必ず「レビュー文」に存在する単語を使用する。捏造は厳禁。
3. 形式厳守:前置きや挨拶は一切出力せず、<STEP1>から<STEP4>の形式のみを出力する。

【分析ステップ定義】
<STEP1> 根拠語句の抽出:
- 正解ラベルに含まれる各カテゴリについて、レビュー文の中から「判定の決め手」となった名詞や評価語句を抽出する。
- 具体的な対象語がない場合（例：「大満足でした」のみ）は、その評価語句自体（「大満足」）を抽出する。
- 文脈文の使用は、レビュー文の代名詞（あれ、それ）を補完する場合のみに限定する。
- 出力形式: 抽出語1|抽出語2|...

<STEP2> カテゴリマッピング:
- <STEP1>で抽出した語句を、正解ラベルに存在するカテゴリ（サービス, 夕食, 朝食, 立地, 設備・アメニティ, 部屋, 風呂）のいずれかに割り当てる。
- 食事のルール: 「食事」としか書かれておらず、正解ラベルに「朝食」「夕食」の両方がある場合は、その語句を両方のカテゴリに紐付ける。
- 全体感想のルール: 「最高」「最悪」などの全体評価語句は、正解ラベルに含まれるすべてのカテゴリに紐付ける。
- 出力形式: 抽出語1→カテゴリA|抽出語2→カテゴリB...

<STEP3> 感情分析:
- 紐付けたカテゴリごとに、なぜその感情値（ポジティブ/ネガティブ）になるのか判定根拠を記述する。
- 根拠と感情極性を短く対応付ける。
- 要望・改善希望（〜してほしい等）はネガティブと判定する。
- 出力形式: カテゴリA→判断根拠→感情値|カテゴリB→判断根拠→感情値...

<STEP4> 最終結果:
- <STEP3>の結果をまとめ、与えられた正解ラベルと完全に一致する形式で出力する。
- 出力形式: カテゴリA:感情値|カテゴリB:感情値...

【参考例】
～


\end{verbatim}
\end{tcolorbox}


\end{document}
