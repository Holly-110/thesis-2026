\documentclass[dvipdfmx]{thesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 基本設定

%\論文名{2025年度 修士論文}
\論文名{2026年度 卒業論文}
%\所属{岐阜大学大学院 自然科学技術研究科 知能理工学専攻 知能情報学領域
\所属{岐阜大学 工学部 電気電子・情報工学科 情報コース}
\学生番号{1243440498}
\氏名{伊藤 柊太朗}
\指導教員{松本 忠博}
\題目{日本語アスペクトカテゴリ感情分析における推論過程の導入による有効性検証}
%\日付{2026年2月x日}
\日付{2026年2月}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ユーザ定義

% …… ご自由に定義してください ……

\usepackage[dvipdfmx]{graphicx}
% 図のディレクトリ
\graphicspath{{./pics/}}

% 定理，定義
%\usepackage{amsthm}
%\theoremstyle{definition}
\newtheorem{theorem}{定理}
\newtheorem{definition}[theorem]{定義}
%\newtheorem*{definition*}{定義}
\newtheorem{example}{例}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% 表紙と目次 (以下はお約束の呪文)
\begin{document}
\maketitle
\frontmatter
\tableofcontents
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{序論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{研究背景}
 近年，インターネットおよび電子商取引（Eコマース）やSNSの普及に伴い，オンライン上のユーザ生成コンテンツ(レビューやSNS投稿など)が爆発的に増加している．これらのレビューや投稿から個々のユーザの意見を分析・理解することは，製品やサービスの改善，およびマーケティング戦略の立案において不可欠である．しかし，膨大なテキストデータを人手で処理することは非効率的であり，多大なコストを要する．そのため，近年は機械学習や深層学習を用いた自然言語処理技術による感情分析が幅広く研究されている．
 
従来の感情分析は，文や文書全体に対してポジティブ，ネガティブ，あるいはニュートラルのいずれか一意の感情極性を判定する手法が主流であった．しかし，実際には一つの文中に複数のトピックが含まれ，それぞれに対して異なる感情が示されることも少なくない．例えば，ホテルやレストランのレビュー文として「料理はおいしいが，店員の態度が悪かった」といったレビュー文がある場合に，この文には，「料理」という側面に対してはポジティブな意見をもち，「店員の態度」に対してはネガティブな意見を持つことが分析できる．上記の例のように，単一の感情極性を割り当てるだけでは，ユーザの多面的な評価を正確に捉えることは困難である．このような課題に対し，文中に含まれる側面（アスペクト）ごとに感情を判定する手法をアスペクトベース感情分析(Aspect Based Sentiment Analysis:  ABSA)という．アスペクトベース感情分析は，従来の感情分析と比較して細粒度な分析が可能であり，ECサイトなどでのレビュー文の分析など多くの場面での実用化が期待され，研究が行われている．
 
しかし，アスペクトベース感情分析はその対象の細かさから，データセットのアノテーションコストが従来の感情分析よりも高いというデメリットがあり，日本語でのデータセット数はかなり少ない．その影響もあり，日本語を対象としたアスペクトベース感情分析の研究はいまだ限定的である．日本語ABSAデータセットとしてよく利用される楽天トラベルレビューデータセットを使用した，日本語でのアスペクトベース感情分析の研究は，数少ない日本語データセットである「楽天トラベルレビューデータセット」を用いた先行研究（西元らによる研究\cite{nishimoto2025}）では，複数のモデルを段階的に用いる分類手法（パイプライン手法）が主眼に置かれてきた．しかし，パイプラインを用いた分類手法には以下の二つの大きな問題点がある．第一に，前段のモデルによる誤りが後続のモデルに波及するエラー伝搬（Error Propagation）の問題である．第二に，文中に直接的な名詞が現れない場合に側面を同定できない暗黙的な側面（暗示的アスペクト）の検出漏れである．これらの問題により，特に日本語特有の文脈依存性の高い表現において，十分な精度を得られないという課題が残されている．

\section{研究の目的}
本研究の目的は，前節で述べた分類モデルを用いたパイプライン手法における課題を解決し，日本語アスペクトカテゴリ感情分類の精度を向上させることである．
具体的には，日本語で事前学習されたT5-baseモデルを用いた生成的手法（Generative Approach）を採用することで，分類モデルを用いた手法よりも表現の幅を広げ、単一のモデル（シングルモデル）による高精度な分析を目指す．さらに，大規模言語モデルの持つ推論能力を学習に取り入れるFine-tune-CoT手法を用いることで，従来手法では困難であった暗示的な意見の抽出精度の向上を図り、日本語アスペクトカテゴリ分析における、中間推論の導入の有効性を検討する。

\section{論文の構成}
本論文の構成は以下の通りである．

\begin{itemize}
    \item \textbf{第2章：事前知識} \\
    本研究の基礎となるアスペクトベース感情分析（ABSA）の定義，および本研究で使用する言語モデルや推論手法に関する事前知識について解説する．
    
    \item \textbf{第3章：関連研究} \\
    日本語ABSAに関する先行研究を概観し，既存の分類手法との違いや本研究の立ち位置について述べる．
    
    \item \textbf{第4章：予備実験：T5モデルによる直接生成手法} \\
    予備実験としてT5モデルを用いた直接生成手法（ベースライン）による検証を行い，直接生成手法における課題，特に暗示的アスペクトの検出漏れについて議論する．
    
    \item \textbf{第5章：提案手法：Fine-tune-CoTを用いた推論過程の導入} \\
    前章で明らかになった課題を解決するための提案手法として，Fine-tune-CoT手法を用いた推論過程の導入について詳述する．ここでは，ボトムアップ型およびトップダウン型の2つの推論パターンについて説明する．
    
    \item \textbf{第6章：評価実験} \\
    提案手法の有効性を検証するための評価実験を行い，ベースライン手法との比較結果および推論精度の分析や定性分析結果について述べる．
    
    \item \textbf{第7章：結論} \\
    本研究で得られた知見をまとめ，結論と今後の課題について述べる．
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{事前知識}
本章では、研究を理解する上で必要となる事前知識について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{アスペクトベース感情分析 (ABSA)}

\subsection{従来の感情分析とその課題}
自然言語処理における感情分析（Sentiment Analysis）は，テキストから著者の主観的な意見や感情を抽出し，その極性（ポジティブ，ネガティブ，ニュートラル）を判定するタスクである．これは製品レビューの分析やSNSのモニタリングなど，マーケティング分野で広く応用されている．

しかし，従来の感情分析は主に文書単位（Document-level）や文単位（Sentence-level）で行われるため，一つの文中に相反する意見が含まれる場合には対応が困難である．
例えば，「料理は美味しいが，店員の態度は悪かった」というレビューに対して，文全体で一つの極性を割り当てようとすると，ユーザの真意（料理への称賛とサービスへの不満）を取りこぼしてしまうことになる．

\subsection{ABSAの定義と4要素}
従来の感情分析（Sentiment Analysis）が，文や文書全体に対して一つの感情極性を判定するのに対し，アスペクトベース感情分析（Aspect-Based Sentiment Analysis: ABSA）は，より細粒度（fine-grained）な意見分析を行うタスクである \cite{survey}．
ABSAでは，主に以下の4つの感情要素（Sentiment Elements）を扱う．

\begin{enumerate}
    \item \textbf{アスペクトカテゴリ ($c$)}:
    事前に定義された属性カテゴリ（例：レストランドメインにおける「料理 (food)」，「サービス (service)」など）．
    
    \item \textbf{アスペクト語 ($a$)}:
    文中に明示的に現れる評価対象の単語（例：「\textbf{ピザ}はおいしい」における「ピザ」）．ターゲットとも呼ばれる．
    
    \item \textbf{意見語 ($o$)}:
    評価対象に対する感情や判断を表す語句（例：「ピザは\textbf{おいしい}」における「おいしい」）．
    
    \item \textbf{感情極性 ($p$)}:
    評価の方向性（ポジティブ，ネガティブ，ニュートラル）．
\end{enumerate}

Zhangら \cite{survey} は，ABSAの問題を「テキスト中の関心のある感情要素（単一または複数の組み合わせ）を特定する問題」と定義している．

\subsection{タスクの分類：単一タスクと複合タスク}
ABSAの研究分野では，目的に応じて多様なサブタスクが提案されている．これらは，抽出対象となる要素の数や関係性に基づき，「単一タスク（Single ABSA Tasks）」と「複合タスク（Compound ABSA Tasks）」に大別される \cite{survey}．

\begin{itemize}
    \item \textbf{単一タスク}: 
    4つの要素のうち，いずれか一つを抽出・分類するタスクである．
    例えば，文中のアスペクト語 $a$ のみを抽出する「アスペクト語抽出 (Aspect Term Extraction: ATE)」や，特定のアスペクトに対する感情極性 $p$ を判定する「アスペクト感情分類 (Aspect Sentiment Classification: ASC)」などがこれに該当する．
    
    \item \textbf{複合タスク}: 
    複数の要素を同時に，かつ相互の関係性を考慮して抽出するタスクである．
    近年では，単一の要素だけでなく，要素間の依存関係を捉えることが重要視されており，アスペクト語と意見語のペア $(a, o)$ を抽出するタスクや，アスペクト・意見・感情の三つ組 $(a, o, p)$ を抽出する「アスペクト感情三つ組抽出 (Aspect Sentiment Triplet Extraction: ASTE)」などが活発に研究されている．
\end{itemize}

\subsection{アスペクトカテゴリ感情分析 (ACSA)}
本研究で扱う「アスペクトカテゴリ感情分析 (Aspect Category Sentiment Analysis: ACSA)」は，入力文に対して「アスペクトカテゴリ ($c$)」と「感情極性 ($p$)」のペア $(c, p)$ を抽出する複合タスクである．

ACSAの最大の特徴は，文中に評価対象を示す具体的な単語（アスペクト語）が存在しない場合でも分析が可能である点である．
例えば，「値段が高すぎる」という文には，「価格」という単語は含まれていないが，ACSAでは「価格 (Price)」カテゴリに対するネガティブな評価として検出することが求められる \cite{survey}．
このように，ACSAは暗示的な意見（Implicit Opinion）を扱う上で実用性が高く，Eコマース等のレビュー分析において重要な役割を果たす．

\section{言語モデルについて}

\subsection{T5}
T5（Text-to-Text Transfer Transformer）\cite{t5} は，2019 年に Google が提案した自然言語処理モデルであり，機械翻訳，文書要約，質問応答，文書分類など多岐にわたるタスクにおいて，当時の最高性能（SOTA）を達成した．T5 は，BERT のようなエンコーダのみのモデルや GPT のようなデコーダのみのモデルとは異なり，Transformer のエンコーダ・デコーダ構成を採用している．その最大の特徴は，あらゆる自然言語処理タスクを「入力テキストを出力テキストに変換する（Text-to-Text）」問題として統一的に扱う点にある．

T5 は，C4（Colossal Clean Crawled Corpus）と呼ばれる大規模なクリーニング済みウェブテキストデータセットを用いて事前学習されている．事前学習タスクとしては，BERT の MLM に似た「スパン破損（Span-corruption）」と呼ばれるタスクが採用されている．これは，入力文中の連続するトークン列（スパン）をランダムにマスクし，デコーダ側でそのマスクされた部分の文字列を生成・復元させるタスクである．これにより，モデルは文脈理解能力とテキスト生成能力を同時に学習することができる．

そして，事前学習した T5 を特定のタスクに適応させるためのファインチューニングにおいても，この Text-to-Text の枠組みが一貫して適用される．BERT のように下流タスクに応じて出力層（分類ヘッドなど）を追加・変更する必要はなく，すべてのタスクで同一のモデル構造と損失関数を使用する．例えば，文書分類タスクであっても，クラスラベルのIDを出力するのではなく，「positive」や「negative」といったラベルのテキストそのものを生成させることで分類を行う．この統一的なアプローチにより，多様なタスクに対して効率的に転移学習を行うことが可能となっている．

本研究では、Wikipediaの日本語ダンプデータ、OSCAR、CC-100の日本語コーパス（約100GB）を用いて事前学習を行ったT5 (Text-to-Text Transfer Transformer) v1.1アーキテクチャのモデル\cite{t5}を使用した。

\subsection{gpt-oss-20B}
gpt-oss-20b\cite{gpt-oss}は，2025年8月に OpenAI が公開したオープンウェイトの推論モデルであり ，エージェントワークフロー内での使用を想定し，Web 検索や Python コード実行などのツール利用や高度な推論能力を備えている ．本モデルは，GPT-2 および GPT-3 のアーキテクチャに基づいた自己回帰的な Mixture-of-Experts（MoE）トランスフォーマーであり ，総パラメータ数は約 209 億（20.9B）である．MXFP4 形式への量子化により重みを 4.25ビットで表現することで，メモリ使用量を削減し，16GBのメモリを持つシステムでも動作可能という特徴がある ．

事前学習には，STEM やコーディング，一般知識に焦点を当てた数兆トークンのテキストデータが用いられており ，CBRN（化学・生物・放射性物質・核）などの有害なコンテンツのフィルタリングも行われている ．事前学習後には，OpenAI o3 と同様の思考の連鎖（Chain-of-Thought）を用いた強化学習（RL）によってポストトレーニングが行われ，推論能力やツール利用能力が強化されている ．

また，システムプロンプトで「low」「medium」「high」の推論レベルを指定することで，タスクに応じた推論の深さを調整できる機能を有している ．さらに，安全性に関しては，意図的なジェイルブレイクへの耐性や，「Instruction Hierarchy（指示の階層）」への準拠を学習させることで，システムメッセージの指示をユーザーメッセージよりも優先させる仕組みが導入されている ．

\section{CoT（chain of thought）}
CoT（Chain-of-Thought Prompting）\cite{CoT}は，2022 年に Google の Wei らによって提案されたプロンプトエンジニアリングの手法であり，算術推論や常識推論，記号推論など，多段階の推論を必要とする複雑なタスクにおいて，大規模言語モデル（LLM）の性能を飛躍的に向上させることが示されている．CoT は，従来の入力に対して直接的な回答のみを求める標準的なプロンプティング（Standard Prompting）とは異なり，最終的な回答に至るまでの「中間的な推論ステップ（intermediate reasoning steps）」と呼ばれる一連の思考過程をモデルに生成させるという特徴がある．

CoT は，主に Few-shot プロンプティングの枠組みで用いられ，モデルに与える数ショットの例示（demonstrations）の中に，質問と回答のペアだけでなく，その回答を導き出すための論理的な思考プロセス（思考の連鎖）を自然言語で記述して含める．これにより，モデルは提示された思考パターンを模倣し，未知の入力に対しても問題を段階的に分解して解くことができるようになる．

\section{Fine-tune-CoT}
Fine-tune-CoT\cite{Fine-turn-CoT}は、KAISTの研究者らによって提案された、大規模言語モデル（LLM）の推論能力を小型モデルに継承させるための学習手法である。従来、複雑な問題を段階的に解く「Chain-of-Thought（CoT）推論」は、パラメータ数が100Bを超える巨大なモデルでのみ発現する創発的能力と考えられてきた。Fine-tune-CoTは、巨大なモデルを「教師」として利用し、そこから得られた推論過程を「生徒」である小型モデルに学習させることで、このモデル規模の制約を打破し、小規模パラメータモデルでも高度な推論を可能にすることを目的としている。

この手法のプロセスは、大きく分けて「推論生成」「精査（キュレーション）」「ファインチューニング」の3つのステップで構成される。まず、GPT-3 175Bなどの巨大な教師モデルに対し、「一歩ずつ考えよう（Let's think step by step）」というZero-shot-CoTプロンプトを用いて、特定の問題に対する中間的な推論ステップ（ラショナル）と回答を生成させる。次に、教師モデルが導き出した回答が正解と一致するものだけをフィルタリングし、「問題」を入力、「推論過程＋回答」を出力とする学習用データセットを作成する。これにより、生徒モデルは単に答えを予測するだけでなく、論理的な思考プロセスそのものを模倣するように学習することができる。

さらに、学習効果を最大化するために多様な推論（Diverse Reasoning）という拡張手法が導入されている。これは、一つの問題に対して教師モデルから複数の異なる推論経路を生成させ、学習データを拡充するアプローチであり、生徒モデルの性能を劇的に向上させる要因となっている。この手法をT5やFlan-T5といった小型のエンコーダ・デコーダ型モデルに適用した結果、特定のタスクにおいて0.3B（3億）規模の極めて小さなモデルが、175Bの教師モデルを凌駕する性能を達成した。Fine-tune-CoTは、巨大モデルへの依存を減らし、実社会のアプリケーションにおいて効率的かつ解釈可能な推論モデルを展開するための重要な道筋を示している

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{関連研究}
本章では，既存手法の説明と本研究の新規性について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{日本語データでのアスペクトベース感情分析における従来手法}
日本語のABSA、特に本研究でも使用する「楽天トラベルレビューデータセット」\cite{rakuten}を用いた研究としては、西元ら による取り組み\cite{nishimoto2025}が挙げられる。彼らは、BERTをベースとした複数の小分類器（Entity ClassifierとAttribute Classifier）を用意し、それらを統合（メタモデル化）することでアスペクトと感情極性を分類する手法（Mpm+Tの改良版）を提案している 。
このような従来の分類（Classification）ベースの手法は、感情分析を「事前に定義されたクラスへの割り当て問題」として扱う。しかし、このアプローチには、ラベル（カテゴリ名や感情極性）が持つ意味情報（Semantics）をモデルが十分に活用できないという課題がある 。また、パイプライン的に複数のモデルを組み合わせる手法は、エラー伝搬のリスクやモデル構成の複雑化を招く可能性がある。
本研究では、よりシンプルで汎用的な単一モデルによる解決を目指し、「テキスト生成（Generation）」として定式化することで、単一のモデルでシンプルかつ高精度な分析を目指す。

\section{生成型アスペクトベース感情分析の進展}
近年、事前学習済み言語モデルの発展に伴い、ABSAタスクをテキスト生成問題として解く生成型アプローチが注目されている。
Zhangら は、T5モデル を用いた統一的な生成フレームワークである **GAS (Generative Aspect-based Sentiment Analysis)** を提案した\cite{gas} 。GASでは、ABSAのタスクをSequence-to-Sequenceの形式に変換し、入力文に対して目的とする感情要素（アスペクト語や感情極性など）を自然言語のテキストとして直接生成させる。特に彼らが提案した「抽出形式 (Extraction-style)」 は、`(アスペクト, 感情)` のようなペアを直接出力系列として学習させることで、従来の分類手法を上回る性能を示した 。

本研究は、このZhangらの生成型アプローチを基礎としている。しかし、GASはあくまで最終的な「答え」を直接生成するものであり、なぜその結論に至ったかという「思考のプロセス」はブラックボックスのままである。
本研究の独自性は、この生成プロセスに 推論過程 (Chain of Thought)を明示的に導入する点にある。特に、文脈中にアスペクト語が明示されない暗示的な意見（Implicit Opinion）に対して、論理的な推論ステップを挟むことで、生成モデルの解釈能力と予測精度のさらなる向上を図る。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{予備実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
本章では、T5モデルによる直接生成手法をベースラインとするための予備実験について述べる。
\section{実験目的}
Zhangらの研究においては、英語のデータセットを用いて、複数のABSAサブタスクをT5モデル を用いた統一的な生成フレームワークであるGAS (Generative Aspect-based Sentiment Analysis)で実装していた。本研究では、先行研究内で行われていなかったアスペクトカテゴリ感情分析の日本語データセットを用いGASを用いたものがどのような精度を示すかベースラインとして実験を行った。また、その際に、レビュー文を入力とする際に文脈情報の有無が精度に与える影響の検証も行った。
\section{実験設定}

\subsection{データセット}
本研究では、楽天グループ株式会社が国立情報学研究所を通じて研究者に提供しているデータセットのアノテーション付きデータである楽天トラベルレビュー: アスペクト・センチメントタグ付きコーパス\cite{rakuten}

\section{実験結果}

\section{分析と考察}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{提案手法：Fine-turn-CoTを用いた推論過程の導入}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{手法の概要}

\section{ボトムアップ型（用語起点）}

\section{トップダウン型（カテゴリ点検）}

\section{損失計算手法}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{評価実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{実験目的}

\section{実験設定}

\section{実験結果}

\section{分析と考察}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結論}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{まとめ}

\section{今後の課題}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{謝辞}

お父さんお母さんありがとう

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{junsrt}  
\bibliography{ref}         

\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{付録}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
